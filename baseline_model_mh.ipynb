{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Micah Holness\n",
    "10/13/2024\n",
    "CSC 8850\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io.wavfile as sw\n",
    "import scipy.signal as ss\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'audio_filepath', 'duration', 'class'], dtype='object')\n",
      "['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# transforming the 1-D time-series into a frequency spectrum\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m fft \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m fft_centered \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfftshift(fft)\n\u001b[0;32m     29\u001b[0m fft_magn \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(np\u001b[38;5;241m.\u001b[39mabs(fft_centered)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mfft\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mholness1\\AppData\\Local\\anaconda3new\\Lib\\site-packages\\numpy\\fft\\_pocketfft.py:215\u001b[0m, in \u001b[0;36mfft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    213\u001b[0m     n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m    214\u001b[0m inv_norm \u001b[38;5;241m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[1;32m--> 215\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_fft\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\mholness1\\AppData\\Local\\anaconda3new\\Lib\\site-packages\\numpy\\fft\\_pocketfft.py:70\u001b[0m, in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m         a \u001b[38;5;241m=\u001b[39m z\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m a\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mpfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     a \u001b[38;5;241m=\u001b[39m swapaxes(a, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import .wav data & labels\n",
    "img_root = \"/Users/mholness1/Desktop/CSC 8850 Project/techcabal-ewe-audio-translation-challenge20240903-4068-o1ckqz/TechCabal Ewe Audio Files-20241014T013956Z-002/TechCabal Ewe Audio Files/\"\n",
    "csv_data = pd.read_csv('./Train.csv', sep=',')\n",
    "print(csv_data.keys())\n",
    "images = csv_data['audio_filepath']\n",
    "labels = csv_data['class']\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "print(unique_labels)\n",
    "labels_class = np.arange(0,len(np.unique(labels)))\n",
    "print(labels_class)\n",
    "\n",
    "# create class to load data into DataLoader (and preprocess)\n",
    "freq_spectrum = []\n",
    "freq_labels = []\n",
    "for widx, wv in enumerate(images):\n",
    "    fpath = os.path.join(img_root, wv)\n",
    "    if os.path.isfile(fpath) == 1:\n",
    "        fs, data = sw.read(fpath)\n",
    "        class_tmp = labels[widx]\n",
    "        cidx = np.where(class_tmp == unique_labels)[0]\n",
    "        freq_labels.append(cidx)\n",
    "        # convert time domain to frequency domain\n",
    "        if len(data.shape) > 1:\n",
    "            data = data[:,0]\n",
    "        # transforming the 1-D time-series into a frequency spectrum\n",
    "        fft = np.fft.fft(data)\n",
    "        fft_centered = np.fft.fftshift(fft)\n",
    "        fft_magn = np.log10(np.abs(fft_centered)**2)\n",
    "        # print(fft_magn.shape)\n",
    "        fft_magn_dwn = ss.resample(fft_magn, 51744, axis=0).astype(np.float32)\n",
    "        freq_spectrum.append(fft_magn_dwn.T)\n",
    "\n",
    "freq_spectrum_arr = np.stack(freq_spectrum, axis=0)\n",
    "freq_labels_arr = np.array(freq_labels)\n",
    "\n",
    "imgs_length = [freq.shape[0] for freq in freq_spectrum_arr]\n",
    "print(np.min(imgs_length))      # 51744\n",
    "\n",
    "np.save('training_data.npy', freq_spectrum_arr)\n",
    "np.save('training_labels.npy', freq_labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 51744)\n",
      "Shapiro-Wilk Statistic: 0.9793568268865794\n",
      "P-value: 3.401083772496944e-09\n",
      "0.0 1.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001CF82512010>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import scipy.stats as stat\n",
    "\n",
    "# load the training data arrays\n",
    "training_data = np.load('./training_data.npy', allow_pickle=True)\n",
    "training_labels = np.load('./training_labels.npy', allow_pickle=True)\n",
    "\n",
    "print(training_data.shape)      # 799, 51744\n",
    "\n",
    "# visualize data (means)\n",
    "fig = plt.figure()\n",
    "plt.scatter(np.arange(0,training_data.shape[0]), np.mean(training_data, axis=1))\n",
    "\n",
    "# Perform the Shapiro-Wilk test ---> test for normality\n",
    "statistic, p_value = stat.shapiro(np.mean(training_data, axis=1))\n",
    "print(\"Shapiro-Wilk Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# note: according to Shapiro-Wilk test, data is significantly skewed\n",
    "# thus, when data is non-normal/non-Gaussian, normalization is preferred [for unknown distribution]\n",
    "# normalize data range = 0 -> 1\n",
    "training_data = (training_data - np.min(training_data)) / (np.max(training_data) - np.min(training_data))\n",
    "print(np.min(training_data), np.max(training_data))\n",
    "\n",
    "# one-hot encode labels\n",
    "training_labels_tmp = torch.tensor(training_labels.flatten())\n",
    "training_labels = nn.functional.one_hot(training_labels_tmp)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.imgs = training_data\n",
    "        self.labels = training_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "dataset = MyDataset()\n",
    "dataloader_train = DataLoader(dataset,\n",
    "                              batch_size=64,\n",
    "                              shuffle=True,\n",
    "                              num_workers=0,\n",
    "                              pin_memory=False)\n",
    "\n",
    "print(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(32, 75, kernel_size=(3,), stride=(1,))\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(75, 100, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(100, 75, kernel_size=(3,), stride=(1,))\n",
      "    (2): Conv1d(75, 32, kernel_size=(3,), stride=(1,))\n",
      "    (3): Conv1d(32, 1, kernel_size=(3,), stride=(1,))\n",
      "    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): AdaptiveAvgPool1d(output_size=100)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=225, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=225, out_features=475, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=475, out_features=210, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=210, out_features=100, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=25, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=25, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your CNN model\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.Conv1d(in_channels=32, out_channels=75, kernel_size=3),\n",
    "            nn.MaxPool1d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=75, out_channels=100, kernel_size=3),\n",
    "            nn.Conv1d(in_channels=100, out_channels=75, kernel_size=3),\n",
    "            nn.Conv1d(in_channels=75, out_channels=32, kernel_size=3),\n",
    "            nn.Conv1d(in_channels=32, out_channels=1, kernel_size=3),\n",
    "            nn.MaxPool1d(kernel_size = 2, stride = 2),\n",
    "            nn.AdaptiveAvgPool1d(100)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(100, 225),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(225, 475),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(475, 210),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(210, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, n_classes)\n",
    "        )     \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, axis=0)\n",
    "        x = torch.permute(x, (1,0,2))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "# set weight initialization\n",
    "def init_weights(model):\n",
    "    \"\"\"Set Conv weights to be He initialization (Kaiming uniform distr) for all Convs\n",
    "        bound = gain x sqrt(3 / fan_mode), \n",
    "        where final tensor has bounds (-bound, +bound) from a uniform distri.\n",
    "        gain (multiplicative factor adjusting weights prior to feeding into neurons), that\n",
    "        has influence on the weight magnitudes, by preserving weight magnitudes in backwards pass (fan_out: n = number of inputs to node)\n",
    "        **** He = recommended for use with ReLU ****\n",
    "    \n",
    "        Linear layer weights are truncated normal distribution\n",
    "        mean = 0, std = 1, with all values within bounds a <= u <= b\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv1d)):\n",
    "            nn.init.kaiming_uniform_(m.weight, mode='fan_out', nonlinearity='relu') \n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "        if isinstance(m, (nn.Linear)):\n",
    "            nn.init.trunc_normal_(m.weight, mean=0.0, std=1.0, a=-2.0, b=2.0, generator=None)\n",
    "    \n",
    "model = MyCNN(n_classes=7)\n",
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "tensor([[0.3752, 0.3994, 0.3925,  ..., 0.3994, 0.3925, 0.3994],\n",
      "        [0.2981, 0.3143, 0.3160,  ..., 0.3089, 0.3160, 0.3143],\n",
      "        [0.2880, 0.2348, 0.2537,  ..., 0.2313, 0.2537, 0.2348],\n",
      "        ...,\n",
      "        [0.4806, 0.4843, 0.4864,  ..., 0.4846, 0.4864, 0.4843],\n",
      "        [0.3287, 0.3244, 0.3550,  ..., 0.3114, 0.3550, 0.3244],\n",
      "        [0.3452, 0.3016, 0.3199,  ..., 0.3368, 0.3199, 0.3016]]) tensor([[0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3981, 0.4190, 0.4136,  ..., 0.4121, 0.4136, 0.4190],\n",
      "        [0.3841, 0.3532, 0.3586,  ..., 0.3536, 0.3586, 0.3532],\n",
      "        [0.3972, 0.3601, 0.3642,  ..., 0.3621, 0.3642, 0.3601],\n",
      "        ...,\n",
      "        [0.4806, 0.4843, 0.4864,  ..., 0.4846, 0.4864, 0.4843],\n",
      "        [0.3122, 0.2499, 0.2601,  ..., 0.2332, 0.2601, 0.2499],\n",
      "        [0.2979, 0.3388, 0.2861,  ..., 0.3167, 0.2861, 0.3388]]) tensor([[0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3202, 0.3211, 0.3029,  ..., 0.2903, 0.3029, 0.3211],\n",
      "        [0.3206, 0.2856, 0.2876,  ..., 0.2917, 0.2876, 0.2856],\n",
      "        [0.3168, 0.2126, 0.2058,  ..., 0.2590, 0.2058, 0.2126],\n",
      "        ...,\n",
      "        [0.3323, 0.3516, 0.3315,  ..., 0.3008, 0.3315, 0.3516],\n",
      "        [0.5152, 0.5234, 0.4999,  ..., 0.5125, 0.4999, 0.5234],\n",
      "        [0.4453, 0.4103, 0.3629,  ..., 0.3796, 0.3629, 0.4103]]) tensor([[0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.2964, 0.3352, 0.3497,  ..., 0.3596, 0.3497, 0.3352],\n",
      "        [0.4720, 0.4689, 0.4701,  ..., 0.4693, 0.4701, 0.4689],\n",
      "        [0.3612, 0.3346, 0.3501,  ..., 0.3341, 0.3501, 0.3346],\n",
      "        ...,\n",
      "        [0.3287, 0.3244, 0.3550,  ..., 0.3114, 0.3550, 0.3244],\n",
      "        [0.3537, 0.2617, 0.2458,  ..., 0.2791, 0.2458, 0.2617],\n",
      "        [0.4736, 0.4773, 0.4805,  ..., 0.4790, 0.4805, 0.4773]]) tensor([[1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3619, 0.2423, 0.2941,  ..., 0.2866, 0.2941, 0.2423],\n",
      "        [0.3501, 0.2751, 0.3698,  ..., 0.2934, 0.3698, 0.2751],\n",
      "        [0.3739, 0.4055, 0.4080,  ..., 0.4057, 0.4080, 0.4055],\n",
      "        ...,\n",
      "        [0.2258, 0.3418, 0.3236,  ..., 0.3195, 0.3236, 0.3418],\n",
      "        [0.3731, 0.4018, 0.3926,  ..., 0.4235, 0.3926, 0.4018],\n",
      "        [0.4365, 0.4326, 0.4314,  ..., 0.4304, 0.4314, 0.4326]]) tensor([[1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3845, 0.3120, 0.3333,  ..., 0.3245, 0.3333, 0.3120],\n",
      "        [0.4282, 0.2933, 0.3305,  ..., 0.4536, 0.3305, 0.2933],\n",
      "        [0.3154, 0.3244, 0.3607,  ..., 0.4322, 0.3607, 0.3244],\n",
      "        ...,\n",
      "        [0.3122, 0.2499, 0.2601,  ..., 0.2332, 0.2601, 0.2499],\n",
      "        [0.3818, 0.4008, 0.4000,  ..., 0.4020, 0.4000, 0.4008],\n",
      "        [0.3845, 0.3805, 0.3741,  ..., 0.3620, 0.3741, 0.3805]]) tensor([[1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3675, 0.3411, 0.3639,  ..., 0.3655, 0.3639, 0.3411],\n",
      "        [0.3972, 0.3601, 0.3642,  ..., 0.3621, 0.3642, 0.3601],\n",
      "        [0.2642, 0.4103, 0.4404,  ..., 0.4118, 0.4404, 0.4103],\n",
      "        ...,\n",
      "        [0.3670, 0.3629, 0.3316,  ..., 0.3442, 0.3316, 0.3629],\n",
      "        [0.2702, 0.3442, 0.3146,  ..., 0.2988, 0.3146, 0.3442],\n",
      "        [0.3726, 0.4150, 0.3719,  ..., 0.4161, 0.3719, 0.4150]]) tensor([[1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.4059, 0.4167, 0.4194,  ..., 0.4148, 0.4194, 0.4167],\n",
      "        [0.3752, 0.3994, 0.3925,  ..., 0.3994, 0.3925, 0.3994],\n",
      "        [0.3901, 0.3790, 0.3773,  ..., 0.3754, 0.3773, 0.3790],\n",
      "        ...,\n",
      "        [0.2702, 0.3442, 0.3146,  ..., 0.2988, 0.3146, 0.3442],\n",
      "        [0.3003, 0.3518, 0.3307,  ..., 0.3463, 0.3307, 0.3518],\n",
      "        [0.3796, 0.4060, 0.3615,  ..., 0.4146, 0.3615, 0.4060]]) tensor([[0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3159, 0.3191, 0.2717,  ..., 0.2991, 0.2717, 0.3191],\n",
      "        [0.3689, 0.3955, 0.3963,  ..., 0.4033, 0.3963, 0.3955],\n",
      "        [0.3828, 0.3453, 0.3484,  ..., 0.3522, 0.3484, 0.3453],\n",
      "        ...,\n",
      "        [0.4201, 0.4065, 0.4048,  ..., 0.4026, 0.4048, 0.4065],\n",
      "        [0.3694, 0.3756, 0.3823,  ..., 0.3551, 0.3823, 0.3756],\n",
      "        [0.3910, 0.3765, 0.3813,  ..., 0.3624, 0.3813, 0.3765]]) tensor([[1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.2953, 0.2220, 0.2343,  ..., 0.2573, 0.2343, 0.2220],\n",
      "        [0.3452, 0.3016, 0.3199,  ..., 0.3368, 0.3199, 0.3016],\n",
      "        [0.2642, 0.4103, 0.4404,  ..., 0.4118, 0.4404, 0.4103],\n",
      "        ...,\n",
      "        [0.3957, 0.3902, 0.3915,  ..., 0.3805, 0.3915, 0.3902],\n",
      "        [0.2953, 0.2220, 0.2343,  ..., 0.2573, 0.2343, 0.2220],\n",
      "        [0.2427, 0.2773, 0.2039,  ..., 0.2293, 0.2039, 0.2773]]) tensor([[0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3238, 0.3092, 0.2888,  ..., 0.2683, 0.2888, 0.3092],\n",
      "        [0.3603, 0.2700, 0.2961,  ..., 0.2894, 0.2961, 0.2700],\n",
      "        [0.4186, 0.4260, 0.4268,  ..., 0.4272, 0.4268, 0.4260],\n",
      "        ...,\n",
      "        [0.2851, 0.3295, 0.3274,  ..., 0.3174, 0.3274, 0.3295],\n",
      "        [0.3433, 0.3018, 0.2703,  ..., 0.2861, 0.2703, 0.3018],\n",
      "        [0.3552, 0.3219, 0.3216,  ..., 0.3285, 0.3216, 0.3219]]) tensor([[0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.4736, 0.4773, 0.4805,  ..., 0.4790, 0.4805, 0.4773],\n",
      "        [0.3193, 0.3155, 0.3185,  ..., 0.3137, 0.3185, 0.3155],\n",
      "        [0.3501, 0.3044, 0.3128,  ..., 0.2748, 0.3128, 0.3044],\n",
      "        ...,\n",
      "        [0.2363, 0.2145, 0.2350,  ..., 0.2458, 0.2350, 0.2145],\n",
      "        [0.2451, 0.2222, 0.2780,  ..., 0.2662, 0.2780, 0.2222],\n",
      "        [0.2293, 0.3528, 0.3621,  ..., 0.3543, 0.3621, 0.3528]]) tensor([[0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0]])\n",
      "<class 'list'>\n",
      "tensor([[0.3258, 0.3350, 0.3256,  ..., 0.3512, 0.3256, 0.3350],\n",
      "        [0.2876, 0.2983, 0.2705,  ..., 0.2810, 0.2705, 0.2983],\n",
      "        [0.3426, 0.2854, 0.2492,  ..., 0.2189, 0.2492, 0.2854],\n",
      "        ...,\n",
      "        [0.3354, 0.2839, 0.2357,  ..., 0.2768, 0.2357, 0.2839],\n",
      "        [0.3385, 0.3504, 0.3502,  ..., 0.3560, 0.3502, 0.3504],\n",
      "        [0.3482, 0.2940, 0.3040,  ..., 0.2971, 0.3040, 0.2940]]) tensor([[1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for didx, data in enumerate(dataloader_train):\n",
    "    print(type(data))\n",
    "    img, label = data\n",
    "    print(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [1/13],               Loss: 1.9220, Accuracy: 0.203125\n",
      "Epoch [1/100], Step [2/13],               Loss: 1.9370, Accuracy: 0.171875\n",
      "Epoch [1/100], Step [3/13],               Loss: 1.8519, Accuracy: 0.34375\n",
      "Epoch [1/100], Step [4/13],               Loss: 1.6672, Accuracy: 0.46875\n",
      "Epoch [1/100], Step [5/13],               Loss: 2.1497, Accuracy: 0.296875\n",
      "Epoch [1/100], Step [6/13],               Loss: 2.1328, Accuracy: 0.125\n",
      "Epoch [1/100], Step [7/13],               Loss: 1.8380, Accuracy: 0.328125\n",
      "Epoch [1/100], Step [8/13],               Loss: 1.8808, Accuracy: 0.203125\n",
      "Epoch [1/100], Step [9/13],               Loss: 1.9196, Accuracy: 0.265625\n",
      "Epoch [1/100], Step [10/13],               Loss: 1.9029, Accuracy: 0.25\n",
      "Epoch [1/100], Step [11/13],               Loss: 1.9317, Accuracy: 0.125\n",
      "Epoch [1/100], Step [12/13],               Loss: 1.9136, Accuracy: 0.1875\n",
      "Epoch [1/100], Step [13/13],               Loss: 1.9099, Accuracy: 0.19354838132858276\n",
      "Epoch [2/100], Step [1/13],               Loss: 1.9478, Accuracy: 0.109375\n",
      "Epoch [2/100], Step [2/13],               Loss: 1.9338, Accuracy: 0.25\n",
      "Epoch [2/100], Step [3/13],               Loss: 1.9351, Accuracy: 0.140625\n",
      "Epoch [2/100], Step [4/13],               Loss: 1.9410, Accuracy: 0.140625\n",
      "Epoch [2/100], Step [5/13],               Loss: 1.9290, Accuracy: 0.109375\n",
      "Epoch [2/100], Step [6/13],               Loss: 1.9358, Accuracy: 0.171875\n",
      "Epoch [2/100], Step [7/13],               Loss: 1.9185, Accuracy: 0.109375\n",
      "Epoch [2/100], Step [8/13],               Loss: 1.9259, Accuracy: 0.25\n",
      "Epoch [2/100], Step [9/13],               Loss: 1.9227, Accuracy: 0.21875\n",
      "Epoch [2/100], Step [10/13],               Loss: 1.9450, Accuracy: 0.171875\n",
      "Epoch [2/100], Step [11/13],               Loss: 1.9002, Accuracy: 0.234375\n",
      "Epoch [2/100], Step [12/13],               Loss: 1.9073, Accuracy: 0.15625\n",
      "Epoch [2/100], Step [13/13],               Loss: 1.8047, Accuracy: 0.32258063554763794\n",
      "Epoch [3/100], Step [1/13],               Loss: 1.8557, Accuracy: 0.34375\n",
      "Epoch [3/100], Step [2/13],               Loss: 1.8626, Accuracy: 0.28125\n",
      "Epoch [3/100], Step [3/13],               Loss: 1.9447, Accuracy: 0.1875\n",
      "Epoch [3/100], Step [4/13],               Loss: 1.8487, Accuracy: 0.3125\n",
      "Epoch [3/100], Step [5/13],               Loss: 1.9821, Accuracy: 0.234375\n",
      "Epoch [3/100], Step [6/13],               Loss: 1.6882, Accuracy: 0.40625\n",
      "Epoch [3/100], Step [7/13],               Loss: 1.8975, Accuracy: 0.1875\n",
      "Epoch [3/100], Step [8/13],               Loss: 1.8335, Accuracy: 0.234375\n",
      "Epoch [3/100], Step [9/13],               Loss: 1.8405, Accuracy: 0.28125\n",
      "Epoch [3/100], Step [10/13],               Loss: 1.9469, Accuracy: 0.234375\n",
      "Epoch [3/100], Step [11/13],               Loss: 1.8027, Accuracy: 0.296875\n",
      "Epoch [3/100], Step [12/13],               Loss: 1.8290, Accuracy: 0.3125\n",
      "Epoch [3/100], Step [13/13],               Loss: 1.9247, Accuracy: 0.22580644488334656\n",
      "Epoch [4/100], Step [1/13],               Loss: 1.8513, Accuracy: 0.3125\n",
      "Epoch [4/100], Step [2/13],               Loss: 1.8718, Accuracy: 0.25\n",
      "Epoch [4/100], Step [3/13],               Loss: 1.8956, Accuracy: 0.3125\n",
      "Epoch [4/100], Step [4/13],               Loss: 1.7601, Accuracy: 0.40625\n",
      "Epoch [4/100], Step [5/13],               Loss: 1.8108, Accuracy: 0.3125\n",
      "Epoch [4/100], Step [6/13],               Loss: 1.8614, Accuracy: 0.25\n",
      "Epoch [4/100], Step [7/13],               Loss: 1.8301, Accuracy: 0.3125\n",
      "Epoch [4/100], Step [8/13],               Loss: 1.9629, Accuracy: 0.203125\n",
      "Epoch [4/100], Step [9/13],               Loss: 1.8533, Accuracy: 0.3125\n",
      "Epoch [4/100], Step [10/13],               Loss: 1.9142, Accuracy: 0.203125\n",
      "Epoch [4/100], Step [11/13],               Loss: 1.9222, Accuracy: 0.171875\n",
      "Epoch [4/100], Step [12/13],               Loss: 1.8337, Accuracy: 0.28125\n",
      "Epoch [4/100], Step [13/13],               Loss: 1.8686, Accuracy: 0.19354838132858276\n",
      "Epoch [5/100], Step [1/13],               Loss: 1.8585, Accuracy: 0.28125\n",
      "Epoch [5/100], Step [2/13],               Loss: 1.8460, Accuracy: 0.296875\n",
      "Epoch [5/100], Step [3/13],               Loss: 1.8958, Accuracy: 0.234375\n",
      "Epoch [5/100], Step [4/13],               Loss: 1.8431, Accuracy: 0.28125\n",
      "Epoch [5/100], Step [5/13],               Loss: 1.8989, Accuracy: 0.234375\n",
      "Epoch [5/100], Step [6/13],               Loss: 1.8605, Accuracy: 0.34375\n",
      "Epoch [5/100], Step [7/13],               Loss: 1.9088, Accuracy: 0.203125\n",
      "Epoch [5/100], Step [8/13],               Loss: 1.8209, Accuracy: 0.296875\n",
      "Epoch [5/100], Step [9/13],               Loss: 1.8338, Accuracy: 0.25\n",
      "Epoch [5/100], Step [10/13],               Loss: 1.8419, Accuracy: 0.28125\n",
      "Epoch [5/100], Step [11/13],               Loss: 1.8437, Accuracy: 0.296875\n",
      "Epoch [5/100], Step [12/13],               Loss: 1.7535, Accuracy: 0.328125\n",
      "Epoch [5/100], Step [13/13],               Loss: 2.0273, Accuracy: 0.19354838132858276\n",
      "Epoch [6/100], Step [1/13],               Loss: 1.9098, Accuracy: 0.296875\n",
      "Epoch [6/100], Step [2/13],               Loss: 1.8350, Accuracy: 0.234375\n",
      "Epoch [6/100], Step [3/13],               Loss: 1.9154, Accuracy: 0.21875\n",
      "Epoch [6/100], Step [4/13],               Loss: 1.8069, Accuracy: 0.296875\n",
      "Epoch [6/100], Step [5/13],               Loss: 1.8292, Accuracy: 0.34375\n",
      "Epoch [6/100], Step [6/13],               Loss: 1.8478, Accuracy: 0.328125\n",
      "Epoch [6/100], Step [7/13],               Loss: 1.8626, Accuracy: 0.265625\n",
      "Epoch [6/100], Step [8/13],               Loss: 1.8996, Accuracy: 0.1875\n",
      "Epoch [6/100], Step [9/13],               Loss: 1.8852, Accuracy: 0.171875\n",
      "Epoch [6/100], Step [10/13],               Loss: 1.8157, Accuracy: 0.3125\n",
      "Epoch [6/100], Step [11/13],               Loss: 1.8149, Accuracy: 0.296875\n",
      "Epoch [6/100], Step [12/13],               Loss: 1.9158, Accuracy: 0.25\n",
      "Epoch [6/100], Step [13/13],               Loss: 1.7421, Accuracy: 0.4516128897666931\n",
      "Epoch [7/100], Step [1/13],               Loss: 1.8716, Accuracy: 0.234375\n",
      "Epoch [7/100], Step [2/13],               Loss: 1.8172, Accuracy: 0.328125\n",
      "Epoch [7/100], Step [3/13],               Loss: 1.9099, Accuracy: 0.234375\n",
      "Epoch [7/100], Step [4/13],               Loss: 1.8489, Accuracy: 0.296875\n",
      "Epoch [7/100], Step [5/13],               Loss: 1.9927, Accuracy: 0.15625\n",
      "Epoch [7/100], Step [6/13],               Loss: 1.8082, Accuracy: 0.359375\n",
      "Epoch [7/100], Step [7/13],               Loss: 1.8228, Accuracy: 0.328125\n",
      "Epoch [7/100], Step [8/13],               Loss: 1.8227, Accuracy: 0.28125\n",
      "Epoch [7/100], Step [9/13],               Loss: 1.8422, Accuracy: 0.3125\n",
      "Epoch [7/100], Step [10/13],               Loss: 1.8381, Accuracy: 0.25\n",
      "Epoch [7/100], Step [11/13],               Loss: 1.8796, Accuracy: 0.28125\n",
      "Epoch [7/100], Step [12/13],               Loss: 1.8233, Accuracy: 0.25\n",
      "Epoch [7/100], Step [13/13],               Loss: 1.8608, Accuracy: 0.22580644488334656\n",
      "Epoch [8/100], Step [1/13],               Loss: 1.8240, Accuracy: 0.328125\n",
      "Epoch [8/100], Step [2/13],               Loss: 1.8779, Accuracy: 0.265625\n",
      "Epoch [8/100], Step [3/13],               Loss: 1.7242, Accuracy: 0.421875\n",
      "Epoch [8/100], Step [4/13],               Loss: 1.8782, Accuracy: 0.265625\n",
      "Epoch [8/100], Step [5/13],               Loss: 1.8897, Accuracy: 0.234375\n",
      "Epoch [8/100], Step [6/13],               Loss: 1.7648, Accuracy: 0.359375\n",
      "Epoch [8/100], Step [7/13],               Loss: 1.8454, Accuracy: 0.296875\n",
      "Epoch [8/100], Step [8/13],               Loss: 1.8549, Accuracy: 0.234375\n",
      "Epoch [8/100], Step [9/13],               Loss: 1.8917, Accuracy: 0.234375\n",
      "Epoch [8/100], Step [10/13],               Loss: 1.8181, Accuracy: 0.328125\n",
      "Epoch [8/100], Step [11/13],               Loss: 1.9047, Accuracy: 0.1875\n",
      "Epoch [8/100], Step [12/13],               Loss: 1.8863, Accuracy: 0.21875\n",
      "Epoch [8/100], Step [13/13],               Loss: 1.9139, Accuracy: 0.09677419066429138\n",
      "Epoch [9/100], Step [1/13],               Loss: 1.8170, Accuracy: 0.375\n",
      "Epoch [9/100], Step [2/13],               Loss: 1.8165, Accuracy: 0.28125\n",
      "Epoch [9/100], Step [3/13],               Loss: 1.9537, Accuracy: 0.140625\n",
      "Epoch [9/100], Step [4/13],               Loss: 1.8511, Accuracy: 0.234375\n",
      "Epoch [9/100], Step [5/13],               Loss: 1.8677, Accuracy: 0.3125\n",
      "Epoch [9/100], Step [6/13],               Loss: 1.8270, Accuracy: 0.3125\n",
      "Epoch [9/100], Step [7/13],               Loss: 1.8699, Accuracy: 0.28125\n",
      "Epoch [9/100], Step [8/13],               Loss: 1.8741, Accuracy: 0.25\n",
      "Epoch [9/100], Step [9/13],               Loss: 1.8090, Accuracy: 0.328125\n",
      "Epoch [9/100], Step [10/13],               Loss: 1.9772, Accuracy: 0.203125\n",
      "Epoch [9/100], Step [11/13],               Loss: 1.8966, Accuracy: 0.234375\n",
      "Epoch [9/100], Step [12/13],               Loss: 1.7790, Accuracy: 0.296875\n",
      "Epoch [9/100], Step [13/13],               Loss: 1.7000, Accuracy: 0.35483869910240173\n",
      "Epoch [10/100], Step [1/13],               Loss: 1.9005, Accuracy: 0.21875\n",
      "Epoch [10/100], Step [2/13],               Loss: 1.8935, Accuracy: 0.28125\n",
      "Epoch [10/100], Step [3/13],               Loss: 1.7996, Accuracy: 0.328125\n",
      "Epoch [10/100], Step [4/13],               Loss: 1.8087, Accuracy: 0.28125\n",
      "Epoch [10/100], Step [5/13],               Loss: 1.8852, Accuracy: 0.25\n",
      "Epoch [10/100], Step [6/13],               Loss: 1.7918, Accuracy: 0.34375\n",
      "Epoch [10/100], Step [7/13],               Loss: 1.8368, Accuracy: 0.328125\n",
      "Epoch [10/100], Step [8/13],               Loss: 1.8394, Accuracy: 0.28125\n",
      "Epoch [10/100], Step [9/13],               Loss: 1.8207, Accuracy: 0.265625\n",
      "Epoch [10/100], Step [10/13],               Loss: 1.9211, Accuracy: 0.203125\n",
      "Epoch [10/100], Step [11/13],               Loss: 1.8997, Accuracy: 0.203125\n",
      "Epoch [10/100], Step [12/13],               Loss: 1.8561, Accuracy: 0.265625\n",
      "Epoch [10/100], Step [13/13],               Loss: 1.7519, Accuracy: 0.35483869910240173\n",
      "Epoch [11/100], Step [1/13],               Loss: 1.8130, Accuracy: 0.265625\n",
      "Epoch [11/100], Step [2/13],               Loss: 1.9056, Accuracy: 0.234375\n",
      "Epoch [11/100], Step [3/13],               Loss: 1.8203, Accuracy: 0.25\n",
      "Epoch [11/100], Step [4/13],               Loss: 1.8803, Accuracy: 0.21875\n",
      "Epoch [11/100], Step [5/13],               Loss: 1.7112, Accuracy: 0.328125\n",
      "Epoch [11/100], Step [6/13],               Loss: 1.8326, Accuracy: 0.328125\n",
      "Epoch [11/100], Step [7/13],               Loss: 1.8597, Accuracy: 0.328125\n",
      "Epoch [11/100], Step [8/13],               Loss: 1.9371, Accuracy: 0.3125\n",
      "Epoch [11/100], Step [9/13],               Loss: 1.8841, Accuracy: 0.296875\n",
      "Epoch [11/100], Step [10/13],               Loss: 1.8375, Accuracy: 0.28125\n",
      "Epoch [11/100], Step [11/13],               Loss: 1.8699, Accuracy: 0.203125\n",
      "Epoch [11/100], Step [12/13],               Loss: 1.8536, Accuracy: 0.265625\n",
      "Epoch [11/100], Step [13/13],               Loss: 1.9077, Accuracy: 0.22580644488334656\n",
      "Epoch [12/100], Step [1/13],               Loss: 1.8909, Accuracy: 0.265625\n",
      "Epoch [12/100], Step [2/13],               Loss: 1.8816, Accuracy: 0.203125\n",
      "Epoch [12/100], Step [3/13],               Loss: 1.8532, Accuracy: 0.3125\n",
      "Epoch [12/100], Step [4/13],               Loss: 1.8459, Accuracy: 0.34375\n",
      "Epoch [12/100], Step [5/13],               Loss: 1.8253, Accuracy: 0.28125\n",
      "Epoch [12/100], Step [6/13],               Loss: 1.9058, Accuracy: 0.234375\n",
      "Epoch [12/100], Step [7/13],               Loss: 1.8667, Accuracy: 0.234375\n",
      "Epoch [12/100], Step [8/13],               Loss: 1.7544, Accuracy: 0.328125\n",
      "Epoch [12/100], Step [9/13],               Loss: 1.8677, Accuracy: 0.265625\n",
      "Epoch [12/100], Step [10/13],               Loss: 1.8721, Accuracy: 0.265625\n",
      "Epoch [12/100], Step [11/13],               Loss: 1.9378, Accuracy: 0.25\n",
      "Epoch [12/100], Step [12/13],               Loss: 1.8198, Accuracy: 0.265625\n",
      "Epoch [12/100], Step [13/13],               Loss: 1.7560, Accuracy: 0.35483869910240173\n",
      "Epoch [13/100], Step [1/13],               Loss: 1.8317, Accuracy: 0.234375\n",
      "Epoch [13/100], Step [2/13],               Loss: 1.8929, Accuracy: 0.296875\n",
      "Epoch [13/100], Step [3/13],               Loss: 1.7509, Accuracy: 0.3125\n",
      "Epoch [13/100], Step [4/13],               Loss: 1.8397, Accuracy: 0.296875\n",
      "Epoch [13/100], Step [5/13],               Loss: 1.8799, Accuracy: 0.28125\n",
      "Epoch [13/100], Step [6/13],               Loss: 1.8063, Accuracy: 0.265625\n",
      "Epoch [13/100], Step [7/13],               Loss: 1.8454, Accuracy: 0.28125\n",
      "Epoch [13/100], Step [8/13],               Loss: 1.8843, Accuracy: 0.25\n",
      "Epoch [13/100], Step [9/13],               Loss: 1.8526, Accuracy: 0.21875\n",
      "Epoch [13/100], Step [10/13],               Loss: 1.9248, Accuracy: 0.21875\n",
      "Epoch [13/100], Step [11/13],               Loss: 1.8650, Accuracy: 0.296875\n",
      "Epoch [13/100], Step [12/13],               Loss: 1.8597, Accuracy: 0.28125\n",
      "Epoch [13/100], Step [13/13],               Loss: 1.7718, Accuracy: 0.3870967626571655\n",
      "Epoch [14/100], Step [1/13],               Loss: 1.8640, Accuracy: 0.265625\n",
      "Epoch [14/100], Step [2/13],               Loss: 1.9962, Accuracy: 0.15625\n",
      "Epoch [14/100], Step [3/13],               Loss: 1.8090, Accuracy: 0.28125\n",
      "Epoch [14/100], Step [4/13],               Loss: 1.8640, Accuracy: 0.28125\n",
      "Epoch [14/100], Step [5/13],               Loss: 1.7763, Accuracy: 0.359375\n",
      "Epoch [14/100], Step [6/13],               Loss: 1.8352, Accuracy: 0.25\n",
      "Epoch [14/100], Step [7/13],               Loss: 1.9103, Accuracy: 0.21875\n",
      "Epoch [14/100], Step [8/13],               Loss: 1.8466, Accuracy: 0.265625\n",
      "Epoch [14/100], Step [9/13],               Loss: 1.8267, Accuracy: 0.296875\n",
      "Epoch [14/100], Step [10/13],               Loss: 1.8496, Accuracy: 0.265625\n",
      "Epoch [14/100], Step [11/13],               Loss: 1.7310, Accuracy: 0.40625\n",
      "Epoch [14/100], Step [12/13],               Loss: 1.8804, Accuracy: 0.234375\n",
      "Epoch [14/100], Step [13/13],               Loss: 1.8150, Accuracy: 0.29032257199287415\n",
      "Epoch [15/100], Step [1/13],               Loss: 1.7548, Accuracy: 0.421875\n",
      "Epoch [15/100], Step [2/13],               Loss: 1.7667, Accuracy: 0.3125\n",
      "Epoch [15/100], Step [3/13],               Loss: 1.7730, Accuracy: 0.359375\n",
      "Epoch [15/100], Step [4/13],               Loss: 1.9542, Accuracy: 0.234375\n",
      "Epoch [15/100], Step [5/13],               Loss: 1.8179, Accuracy: 0.25\n",
      "Epoch [15/100], Step [6/13],               Loss: 1.8731, Accuracy: 0.265625\n",
      "Epoch [15/100], Step [7/13],               Loss: 1.7708, Accuracy: 0.28125\n",
      "Epoch [15/100], Step [8/13],               Loss: 1.8298, Accuracy: 0.328125\n",
      "Epoch [15/100], Step [9/13],               Loss: 1.9303, Accuracy: 0.21875\n",
      "Epoch [15/100], Step [10/13],               Loss: 1.8661, Accuracy: 0.28125\n",
      "Epoch [15/100], Step [11/13],               Loss: 1.8927, Accuracy: 0.171875\n",
      "Epoch [15/100], Step [12/13],               Loss: 1.8886, Accuracy: 0.21875\n",
      "Epoch [15/100], Step [13/13],               Loss: 1.9536, Accuracy: 0.16129031777381897\n",
      "Epoch [16/100], Step [1/13],               Loss: 1.8570, Accuracy: 0.3125\n",
      "Epoch [16/100], Step [2/13],               Loss: 1.8598, Accuracy: 0.25\n",
      "Epoch [16/100], Step [3/13],               Loss: 1.8730, Accuracy: 0.265625\n",
      "Epoch [16/100], Step [4/13],               Loss: 1.8235, Accuracy: 0.34375\n",
      "Epoch [16/100], Step [5/13],               Loss: 1.9229, Accuracy: 0.234375\n",
      "Epoch [16/100], Step [6/13],               Loss: 1.8970, Accuracy: 0.203125\n",
      "Epoch [16/100], Step [7/13],               Loss: 1.8966, Accuracy: 0.265625\n",
      "Epoch [16/100], Step [8/13],               Loss: 1.7952, Accuracy: 0.3125\n",
      "Epoch [16/100], Step [9/13],               Loss: 1.7842, Accuracy: 0.34375\n",
      "Epoch [16/100], Step [10/13],               Loss: 1.8340, Accuracy: 0.28125\n",
      "Epoch [16/100], Step [11/13],               Loss: 1.8809, Accuracy: 0.25\n",
      "Epoch [16/100], Step [12/13],               Loss: 1.8344, Accuracy: 0.234375\n",
      "Epoch [16/100], Step [13/13],               Loss: 1.8276, Accuracy: 0.25806450843811035\n",
      "Epoch [17/100], Step [1/13],               Loss: 1.7633, Accuracy: 0.390625\n",
      "Epoch [17/100], Step [2/13],               Loss: 1.8070, Accuracy: 0.28125\n",
      "Epoch [17/100], Step [3/13],               Loss: 1.8263, Accuracy: 0.34375\n",
      "Epoch [17/100], Step [4/13],               Loss: 1.8793, Accuracy: 0.21875\n",
      "Epoch [17/100], Step [5/13],               Loss: 1.9189, Accuracy: 0.21875\n",
      "Epoch [17/100], Step [6/13],               Loss: 1.8249, Accuracy: 0.34375\n",
      "Epoch [17/100], Step [7/13],               Loss: 1.8870, Accuracy: 0.203125\n",
      "Epoch [17/100], Step [8/13],               Loss: 1.8846, Accuracy: 0.265625\n",
      "Epoch [17/100], Step [9/13],               Loss: 1.8355, Accuracy: 0.3125\n",
      "Epoch [17/100], Step [10/13],               Loss: 1.8439, Accuracy: 0.21875\n",
      "Epoch [17/100], Step [11/13],               Loss: 1.8298, Accuracy: 0.234375\n",
      "Epoch [17/100], Step [12/13],               Loss: 1.9196, Accuracy: 0.234375\n",
      "Epoch [17/100], Step [13/13],               Loss: 1.8488, Accuracy: 0.32258063554763794\n",
      "Epoch [18/100], Step [1/13],               Loss: 1.8742, Accuracy: 0.25\n",
      "Epoch [18/100], Step [2/13],               Loss: 1.9095, Accuracy: 0.28125\n",
      "Epoch [18/100], Step [3/13],               Loss: 1.8381, Accuracy: 0.265625\n",
      "Epoch [18/100], Step [4/13],               Loss: 1.8664, Accuracy: 0.296875\n",
      "Epoch [18/100], Step [5/13],               Loss: 1.6840, Accuracy: 0.4375\n",
      "Epoch [18/100], Step [6/13],               Loss: 1.9100, Accuracy: 0.25\n",
      "Epoch [18/100], Step [7/13],               Loss: 1.7484, Accuracy: 0.28125\n",
      "Epoch [18/100], Step [8/13],               Loss: 1.8982, Accuracy: 0.203125\n",
      "Epoch [18/100], Step [9/13],               Loss: 1.8557, Accuracy: 0.34375\n",
      "Epoch [18/100], Step [10/13],               Loss: 1.9339, Accuracy: 0.21875\n",
      "Epoch [18/100], Step [11/13],               Loss: 1.8689, Accuracy: 0.234375\n",
      "Epoch [18/100], Step [12/13],               Loss: 1.8701, Accuracy: 0.203125\n",
      "Epoch [18/100], Step [13/13],               Loss: 1.8138, Accuracy: 0.32258063554763794\n",
      "Epoch [19/100], Step [1/13],               Loss: 1.8516, Accuracy: 0.34375\n",
      "Epoch [19/100], Step [2/13],               Loss: 1.8353, Accuracy: 0.3125\n",
      "Epoch [19/100], Step [3/13],               Loss: 1.7913, Accuracy: 0.34375\n",
      "Epoch [19/100], Step [4/13],               Loss: 1.8818, Accuracy: 0.25\n",
      "Epoch [19/100], Step [5/13],               Loss: 1.8044, Accuracy: 0.3125\n",
      "Epoch [19/100], Step [6/13],               Loss: 1.9587, Accuracy: 0.15625\n",
      "Epoch [19/100], Step [7/13],               Loss: 1.7263, Accuracy: 0.421875\n",
      "Epoch [19/100], Step [8/13],               Loss: 1.8643, Accuracy: 0.28125\n",
      "Epoch [19/100], Step [9/13],               Loss: 1.8844, Accuracy: 0.1875\n",
      "Epoch [19/100], Step [10/13],               Loss: 1.8438, Accuracy: 0.296875\n",
      "Epoch [19/100], Step [11/13],               Loss: 1.9382, Accuracy: 0.234375\n",
      "Epoch [19/100], Step [12/13],               Loss: 1.9170, Accuracy: 0.171875\n",
      "Epoch [19/100], Step [13/13],               Loss: 1.8598, Accuracy: 0.22580644488334656\n",
      "Epoch [20/100], Step [1/13],               Loss: 1.8178, Accuracy: 0.3125\n",
      "Epoch [20/100], Step [2/13],               Loss: 1.8978, Accuracy: 0.15625\n",
      "Epoch [20/100], Step [3/13],               Loss: 1.8738, Accuracy: 0.3125\n",
      "Epoch [20/100], Step [4/13],               Loss: 1.8466, Accuracy: 0.296875\n",
      "Epoch [20/100], Step [5/13],               Loss: 1.8620, Accuracy: 0.234375\n",
      "Epoch [20/100], Step [6/13],               Loss: 1.7766, Accuracy: 0.265625\n",
      "Epoch [20/100], Step [7/13],               Loss: 1.8537, Accuracy: 0.3125\n",
      "Epoch [20/100], Step [8/13],               Loss: 1.8234, Accuracy: 0.28125\n",
      "Epoch [20/100], Step [9/13],               Loss: 1.9093, Accuracy: 0.25\n",
      "Epoch [20/100], Step [10/13],               Loss: 1.9635, Accuracy: 0.234375\n",
      "Epoch [20/100], Step [11/13],               Loss: 1.9049, Accuracy: 0.28125\n",
      "Epoch [20/100], Step [12/13],               Loss: 1.8285, Accuracy: 0.328125\n",
      "Epoch [20/100], Step [13/13],               Loss: 1.8523, Accuracy: 0.32258063554763794\n",
      "Epoch [21/100], Step [1/13],               Loss: 1.8165, Accuracy: 0.328125\n",
      "Epoch [21/100], Step [2/13],               Loss: 1.8801, Accuracy: 0.296875\n",
      "Epoch [21/100], Step [3/13],               Loss: 1.8744, Accuracy: 0.296875\n",
      "Epoch [21/100], Step [4/13],               Loss: 1.8260, Accuracy: 0.28125\n",
      "Epoch [21/100], Step [5/13],               Loss: 1.8183, Accuracy: 0.296875\n",
      "Epoch [21/100], Step [6/13],               Loss: 1.8194, Accuracy: 0.296875\n",
      "Epoch [21/100], Step [7/13],               Loss: 1.8438, Accuracy: 0.28125\n",
      "Epoch [21/100], Step [8/13],               Loss: 1.8666, Accuracy: 0.265625\n",
      "Epoch [21/100], Step [9/13],               Loss: 1.8785, Accuracy: 0.25\n",
      "Epoch [21/100], Step [10/13],               Loss: 1.8157, Accuracy: 0.28125\n",
      "Epoch [21/100], Step [11/13],               Loss: 1.9851, Accuracy: 0.203125\n",
      "Epoch [21/100], Step [12/13],               Loss: 1.8544, Accuracy: 0.21875\n",
      "Epoch [21/100], Step [13/13],               Loss: 1.8210, Accuracy: 0.25806450843811035\n",
      "Epoch [22/100], Step [1/13],               Loss: 1.8683, Accuracy: 0.265625\n",
      "Epoch [22/100], Step [2/13],               Loss: 1.8707, Accuracy: 0.296875\n",
      "Epoch [22/100], Step [3/13],               Loss: 1.8472, Accuracy: 0.28125\n",
      "Epoch [22/100], Step [4/13],               Loss: 1.8727, Accuracy: 0.203125\n",
      "Epoch [22/100], Step [5/13],               Loss: 1.8329, Accuracy: 0.359375\n",
      "Epoch [22/100], Step [6/13],               Loss: 1.8590, Accuracy: 0.3125\n",
      "Epoch [22/100], Step [7/13],               Loss: 1.8356, Accuracy: 0.34375\n",
      "Epoch [22/100], Step [8/13],               Loss: 1.8251, Accuracy: 0.296875\n",
      "Epoch [22/100], Step [9/13],               Loss: 1.8326, Accuracy: 0.25\n",
      "Epoch [22/100], Step [10/13],               Loss: 1.9226, Accuracy: 0.21875\n",
      "Epoch [22/100], Step [11/13],               Loss: 1.8488, Accuracy: 0.265625\n",
      "Epoch [22/100], Step [12/13],               Loss: 1.8538, Accuracy: 0.203125\n",
      "Epoch [22/100], Step [13/13],               Loss: 1.8553, Accuracy: 0.25806450843811035\n",
      "Epoch [23/100], Step [1/13],               Loss: 1.8574, Accuracy: 0.21875\n",
      "Epoch [23/100], Step [2/13],               Loss: 1.8197, Accuracy: 0.21875\n",
      "Epoch [23/100], Step [3/13],               Loss: 1.8598, Accuracy: 0.25\n",
      "Epoch [23/100], Step [4/13],               Loss: 1.8103, Accuracy: 0.390625\n",
      "Epoch [23/100], Step [5/13],               Loss: 1.8683, Accuracy: 0.25\n",
      "Epoch [23/100], Step [6/13],               Loss: 1.7915, Accuracy: 0.3125\n",
      "Epoch [23/100], Step [7/13],               Loss: 1.8844, Accuracy: 0.203125\n",
      "Epoch [23/100], Step [8/13],               Loss: 1.9199, Accuracy: 0.25\n",
      "Epoch [23/100], Step [9/13],               Loss: 1.9109, Accuracy: 0.234375\n",
      "Epoch [23/100], Step [10/13],               Loss: 1.7880, Accuracy: 0.359375\n",
      "Epoch [23/100], Step [11/13],               Loss: 1.8852, Accuracy: 0.34375\n",
      "Epoch [23/100], Step [12/13],               Loss: 1.8025, Accuracy: 0.265625\n",
      "Epoch [23/100], Step [13/13],               Loss: 1.9573, Accuracy: 0.25806450843811035\n",
      "Epoch [24/100], Step [1/13],               Loss: 1.7726, Accuracy: 0.34375\n",
      "Epoch [24/100], Step [2/13],               Loss: 1.8267, Accuracy: 0.265625\n",
      "Epoch [24/100], Step [3/13],               Loss: 1.8890, Accuracy: 0.203125\n",
      "Epoch [24/100], Step [4/13],               Loss: 1.7846, Accuracy: 0.359375\n",
      "Epoch [24/100], Step [5/13],               Loss: 1.9043, Accuracy: 0.25\n",
      "Epoch [24/100], Step [6/13],               Loss: 1.8189, Accuracy: 0.34375\n",
      "Epoch [24/100], Step [7/13],               Loss: 1.8833, Accuracy: 0.1875\n",
      "Epoch [24/100], Step [8/13],               Loss: 1.8870, Accuracy: 0.265625\n",
      "Epoch [24/100], Step [9/13],               Loss: 1.8800, Accuracy: 0.171875\n",
      "Epoch [24/100], Step [10/13],               Loss: 1.8426, Accuracy: 0.296875\n",
      "Epoch [24/100], Step [11/13],               Loss: 1.8359, Accuracy: 0.3125\n",
      "Epoch [24/100], Step [12/13],               Loss: 1.8626, Accuracy: 0.296875\n",
      "Epoch [24/100], Step [13/13],               Loss: 1.8787, Accuracy: 0.25806450843811035\n",
      "Epoch [25/100], Step [1/13],               Loss: 1.8709, Accuracy: 0.265625\n",
      "Epoch [25/100], Step [2/13],               Loss: 1.8417, Accuracy: 0.265625\n",
      "Epoch [25/100], Step [3/13],               Loss: 1.8079, Accuracy: 0.375\n",
      "Epoch [25/100], Step [4/13],               Loss: 1.8626, Accuracy: 0.328125\n",
      "Epoch [25/100], Step [5/13],               Loss: 1.8248, Accuracy: 0.296875\n",
      "Epoch [25/100], Step [6/13],               Loss: 1.8665, Accuracy: 0.21875\n",
      "Epoch [25/100], Step [7/13],               Loss: 1.7552, Accuracy: 0.28125\n",
      "Epoch [25/100], Step [8/13],               Loss: 1.9009, Accuracy: 0.25\n",
      "Epoch [25/100], Step [9/13],               Loss: 1.9096, Accuracy: 0.1875\n",
      "Epoch [25/100], Step [10/13],               Loss: 1.9062, Accuracy: 0.265625\n",
      "Epoch [25/100], Step [11/13],               Loss: 1.8751, Accuracy: 0.28125\n",
      "Epoch [25/100], Step [12/13],               Loss: 1.8458, Accuracy: 0.265625\n",
      "Epoch [25/100], Step [13/13],               Loss: 1.8196, Accuracy: 0.29032257199287415\n",
      "Epoch [26/100], Step [1/13],               Loss: 1.8455, Accuracy: 0.328125\n",
      "Epoch [26/100], Step [2/13],               Loss: 1.9020, Accuracy: 0.171875\n",
      "Epoch [26/100], Step [3/13],               Loss: 1.8099, Accuracy: 0.328125\n",
      "Epoch [26/100], Step [4/13],               Loss: 1.8695, Accuracy: 0.234375\n",
      "Epoch [26/100], Step [5/13],               Loss: 1.8427, Accuracy: 0.3125\n",
      "Epoch [26/100], Step [6/13],               Loss: 1.8830, Accuracy: 0.3125\n",
      "Epoch [26/100], Step [7/13],               Loss: 1.8275, Accuracy: 0.1875\n",
      "Epoch [26/100], Step [8/13],               Loss: 1.8849, Accuracy: 0.21875\n",
      "Epoch [26/100], Step [9/13],               Loss: 1.8805, Accuracy: 0.265625\n",
      "Epoch [26/100], Step [10/13],               Loss: 1.9928, Accuracy: 0.21875\n",
      "Epoch [26/100], Step [11/13],               Loss: 1.7181, Accuracy: 0.40625\n",
      "Epoch [26/100], Step [12/13],               Loss: 1.7980, Accuracy: 0.3125\n",
      "Epoch [26/100], Step [13/13],               Loss: 1.8910, Accuracy: 0.25806450843811035\n",
      "Epoch [27/100], Step [1/13],               Loss: 1.8625, Accuracy: 0.28125\n",
      "Epoch [27/100], Step [2/13],               Loss: 1.7850, Accuracy: 0.34375\n",
      "Epoch [27/100], Step [3/13],               Loss: 1.8488, Accuracy: 0.234375\n",
      "Epoch [27/100], Step [4/13],               Loss: 1.8720, Accuracy: 0.28125\n",
      "Epoch [27/100], Step [5/13],               Loss: 1.8712, Accuracy: 0.234375\n",
      "Epoch [27/100], Step [6/13],               Loss: 1.7758, Accuracy: 0.296875\n",
      "Epoch [27/100], Step [7/13],               Loss: 1.9633, Accuracy: 0.1875\n",
      "Epoch [27/100], Step [8/13],               Loss: 1.8386, Accuracy: 0.359375\n",
      "Epoch [27/100], Step [9/13],               Loss: 1.8007, Accuracy: 0.3125\n",
      "Epoch [27/100], Step [10/13],               Loss: 1.9260, Accuracy: 0.25\n",
      "Epoch [27/100], Step [11/13],               Loss: 1.8387, Accuracy: 0.25\n",
      "Epoch [27/100], Step [12/13],               Loss: 1.8168, Accuracy: 0.25\n",
      "Epoch [27/100], Step [13/13],               Loss: 1.8220, Accuracy: 0.29032257199287415\n",
      "Epoch [28/100], Step [1/13],               Loss: 1.8272, Accuracy: 0.328125\n",
      "Epoch [28/100], Step [2/13],               Loss: 1.8353, Accuracy: 0.25\n",
      "Epoch [28/100], Step [3/13],               Loss: 1.8556, Accuracy: 0.265625\n",
      "Epoch [28/100], Step [4/13],               Loss: 1.8921, Accuracy: 0.296875\n",
      "Epoch [28/100], Step [5/13],               Loss: 1.8728, Accuracy: 0.1875\n",
      "Epoch [28/100], Step [6/13],               Loss: 1.8878, Accuracy: 0.21875\n",
      "Epoch [28/100], Step [7/13],               Loss: 1.8085, Accuracy: 0.328125\n",
      "Epoch [28/100], Step [8/13],               Loss: 1.7297, Accuracy: 0.4375\n",
      "Epoch [28/100], Step [9/13],               Loss: 1.8634, Accuracy: 0.296875\n",
      "Epoch [28/100], Step [10/13],               Loss: 1.9085, Accuracy: 0.1875\n",
      "Epoch [28/100], Step [11/13],               Loss: 1.8299, Accuracy: 0.28125\n",
      "Epoch [28/100], Step [12/13],               Loss: 1.8908, Accuracy: 0.25\n",
      "Epoch [28/100], Step [13/13],               Loss: 1.8165, Accuracy: 0.19354838132858276\n",
      "Epoch [29/100], Step [1/13],               Loss: 1.7996, Accuracy: 0.28125\n",
      "Epoch [29/100], Step [2/13],               Loss: 1.8484, Accuracy: 0.296875\n",
      "Epoch [29/100], Step [3/13],               Loss: 1.8388, Accuracy: 0.28125\n",
      "Epoch [29/100], Step [4/13],               Loss: 1.8389, Accuracy: 0.296875\n",
      "Epoch [29/100], Step [5/13],               Loss: 1.8029, Accuracy: 0.3125\n",
      "Epoch [29/100], Step [6/13],               Loss: 1.8666, Accuracy: 0.203125\n",
      "Epoch [29/100], Step [7/13],               Loss: 1.8625, Accuracy: 0.25\n",
      "Epoch [29/100], Step [8/13],               Loss: 1.9407, Accuracy: 0.28125\n",
      "Epoch [29/100], Step [9/13],               Loss: 1.9177, Accuracy: 0.21875\n",
      "Epoch [29/100], Step [10/13],               Loss: 1.8897, Accuracy: 0.203125\n",
      "Epoch [29/100], Step [11/13],               Loss: 1.8099, Accuracy: 0.359375\n",
      "Epoch [29/100], Step [12/13],               Loss: 1.8651, Accuracy: 0.234375\n",
      "Epoch [29/100], Step [13/13],               Loss: 1.7331, Accuracy: 0.4193548262119293\n",
      "Epoch [30/100], Step [1/13],               Loss: 1.8389, Accuracy: 0.234375\n",
      "Epoch [30/100], Step [2/13],               Loss: 1.8328, Accuracy: 0.265625\n",
      "Epoch [30/100], Step [3/13],               Loss: 1.8723, Accuracy: 0.265625\n",
      "Epoch [30/100], Step [4/13],               Loss: 1.8085, Accuracy: 0.3125\n",
      "Epoch [30/100], Step [5/13],               Loss: 1.9042, Accuracy: 0.265625\n",
      "Epoch [30/100], Step [6/13],               Loss: 1.8221, Accuracy: 0.296875\n",
      "Epoch [30/100], Step [7/13],               Loss: 1.8885, Accuracy: 0.3125\n",
      "Epoch [30/100], Step [8/13],               Loss: 1.8601, Accuracy: 0.21875\n",
      "Epoch [30/100], Step [9/13],               Loss: 1.8847, Accuracy: 0.203125\n",
      "Epoch [30/100], Step [10/13],               Loss: 1.8408, Accuracy: 0.328125\n",
      "Epoch [30/100], Step [11/13],               Loss: 1.8054, Accuracy: 0.3125\n",
      "Epoch [30/100], Step [12/13],               Loss: 1.8761, Accuracy: 0.25\n",
      "Epoch [30/100], Step [13/13],               Loss: 1.8379, Accuracy: 0.32258063554763794\n",
      "Epoch [31/100], Step [1/13],               Loss: 1.8559, Accuracy: 0.3125\n",
      "Epoch [31/100], Step [2/13],               Loss: 1.8332, Accuracy: 0.265625\n",
      "Epoch [31/100], Step [3/13],               Loss: 1.7321, Accuracy: 0.34375\n",
      "Epoch [31/100], Step [4/13],               Loss: 1.9170, Accuracy: 0.234375\n",
      "Epoch [31/100], Step [5/13],               Loss: 1.8882, Accuracy: 0.25\n",
      "Epoch [31/100], Step [6/13],               Loss: 1.8938, Accuracy: 0.21875\n",
      "Epoch [31/100], Step [7/13],               Loss: 1.8509, Accuracy: 0.234375\n",
      "Epoch [31/100], Step [8/13],               Loss: 1.8112, Accuracy: 0.25\n",
      "Epoch [31/100], Step [9/13],               Loss: 1.8963, Accuracy: 0.21875\n",
      "Epoch [31/100], Step [10/13],               Loss: 1.8358, Accuracy: 0.265625\n",
      "Epoch [31/100], Step [11/13],               Loss: 1.8353, Accuracy: 0.359375\n",
      "Epoch [31/100], Step [12/13],               Loss: 1.8799, Accuracy: 0.328125\n",
      "Epoch [31/100], Step [13/13],               Loss: 1.8141, Accuracy: 0.29032257199287415\n",
      "Epoch [32/100], Step [1/13],               Loss: 1.7840, Accuracy: 0.328125\n",
      "Epoch [32/100], Step [2/13],               Loss: 1.8824, Accuracy: 0.265625\n",
      "Epoch [32/100], Step [3/13],               Loss: 1.9260, Accuracy: 0.171875\n",
      "Epoch [32/100], Step [4/13],               Loss: 1.7801, Accuracy: 0.328125\n",
      "Epoch [32/100], Step [5/13],               Loss: 1.8219, Accuracy: 0.265625\n",
      "Epoch [32/100], Step [6/13],               Loss: 1.8322, Accuracy: 0.234375\n",
      "Epoch [32/100], Step [7/13],               Loss: 1.7796, Accuracy: 0.3125\n",
      "Epoch [32/100], Step [8/13],               Loss: 1.9229, Accuracy: 0.265625\n",
      "Epoch [32/100], Step [9/13],               Loss: 1.7724, Accuracy: 0.34375\n",
      "Epoch [32/100], Step [10/13],               Loss: 1.8881, Accuracy: 0.296875\n",
      "Epoch [32/100], Step [11/13],               Loss: 1.8730, Accuracy: 0.265625\n",
      "Epoch [32/100], Step [12/13],               Loss: 1.9337, Accuracy: 0.203125\n",
      "Epoch [32/100], Step [13/13],               Loss: 1.7893, Accuracy: 0.29032257199287415\n",
      "Epoch [33/100], Step [1/13],               Loss: 1.8114, Accuracy: 0.296875\n",
      "Epoch [33/100], Step [2/13],               Loss: 1.8825, Accuracy: 0.25\n",
      "Epoch [33/100], Step [3/13],               Loss: 1.9350, Accuracy: 0.15625\n",
      "Epoch [33/100], Step [4/13],               Loss: 1.7883, Accuracy: 0.359375\n",
      "Epoch [33/100], Step [5/13],               Loss: 1.8733, Accuracy: 0.28125\n",
      "Epoch [33/100], Step [6/13],               Loss: 1.7694, Accuracy: 0.328125\n",
      "Epoch [33/100], Step [7/13],               Loss: 1.7754, Accuracy: 0.3125\n",
      "Epoch [33/100], Step [8/13],               Loss: 1.8266, Accuracy: 0.234375\n",
      "Epoch [33/100], Step [9/13],               Loss: 1.8562, Accuracy: 0.28125\n",
      "Epoch [33/100], Step [10/13],               Loss: 1.9356, Accuracy: 0.25\n",
      "Epoch [33/100], Step [11/13],               Loss: 1.9259, Accuracy: 0.28125\n",
      "Epoch [33/100], Step [12/13],               Loss: 1.8597, Accuracy: 0.28125\n",
      "Epoch [33/100], Step [13/13],               Loss: 1.8752, Accuracy: 0.22580644488334656\n",
      "Epoch [34/100], Step [1/13],               Loss: 1.8892, Accuracy: 0.25\n",
      "Epoch [34/100], Step [2/13],               Loss: 1.9027, Accuracy: 0.21875\n",
      "Epoch [34/100], Step [3/13],               Loss: 1.8782, Accuracy: 0.234375\n",
      "Epoch [34/100], Step [4/13],               Loss: 1.8466, Accuracy: 0.359375\n",
      "Epoch [34/100], Step [5/13],               Loss: 1.9103, Accuracy: 0.1875\n",
      "Epoch [34/100], Step [6/13],               Loss: 1.8598, Accuracy: 0.296875\n",
      "Epoch [34/100], Step [7/13],               Loss: 1.8683, Accuracy: 0.328125\n",
      "Epoch [34/100], Step [8/13],               Loss: 1.8769, Accuracy: 0.25\n",
      "Epoch [34/100], Step [9/13],               Loss: 1.8280, Accuracy: 0.265625\n",
      "Epoch [34/100], Step [10/13],               Loss: 1.8267, Accuracy: 0.265625\n",
      "Epoch [34/100], Step [11/13],               Loss: 1.7646, Accuracy: 0.328125\n",
      "Epoch [34/100], Step [12/13],               Loss: 1.8670, Accuracy: 0.234375\n",
      "Epoch [34/100], Step [13/13],               Loss: 1.7290, Accuracy: 0.4193548262119293\n",
      "Epoch [35/100], Step [1/13],               Loss: 1.8435, Accuracy: 0.265625\n",
      "Epoch [35/100], Step [2/13],               Loss: 1.8554, Accuracy: 0.328125\n",
      "Epoch [35/100], Step [3/13],               Loss: 1.8199, Accuracy: 0.265625\n",
      "Epoch [35/100], Step [4/13],               Loss: 1.8220, Accuracy: 0.234375\n",
      "Epoch [35/100], Step [5/13],               Loss: 1.8659, Accuracy: 0.203125\n",
      "Epoch [35/100], Step [6/13],               Loss: 1.8269, Accuracy: 0.359375\n",
      "Epoch [35/100], Step [7/13],               Loss: 1.8240, Accuracy: 0.25\n",
      "Epoch [35/100], Step [8/13],               Loss: 1.8320, Accuracy: 0.296875\n",
      "Epoch [35/100], Step [9/13],               Loss: 1.8750, Accuracy: 0.28125\n",
      "Epoch [35/100], Step [10/13],               Loss: 1.8690, Accuracy: 0.25\n",
      "Epoch [35/100], Step [11/13],               Loss: 1.9192, Accuracy: 0.203125\n",
      "Epoch [35/100], Step [12/13],               Loss: 1.9038, Accuracy: 0.25\n",
      "Epoch [35/100], Step [13/13],               Loss: 1.8267, Accuracy: 0.4838709533214569\n",
      "Epoch [36/100], Step [1/13],               Loss: 1.7736, Accuracy: 0.375\n",
      "Epoch [36/100], Step [2/13],               Loss: 1.8679, Accuracy: 0.203125\n",
      "Epoch [36/100], Step [3/13],               Loss: 1.8713, Accuracy: 0.234375\n",
      "Epoch [36/100], Step [4/13],               Loss: 1.8246, Accuracy: 0.3125\n",
      "Epoch [36/100], Step [5/13],               Loss: 1.8878, Accuracy: 0.25\n",
      "Epoch [36/100], Step [6/13],               Loss: 1.7765, Accuracy: 0.328125\n",
      "Epoch [36/100], Step [7/13],               Loss: 1.9200, Accuracy: 0.1875\n",
      "Epoch [36/100], Step [8/13],               Loss: 1.9143, Accuracy: 0.25\n",
      "Epoch [36/100], Step [9/13],               Loss: 1.8575, Accuracy: 0.25\n",
      "Epoch [36/100], Step [10/13],               Loss: 1.8089, Accuracy: 0.3125\n",
      "Epoch [36/100], Step [11/13],               Loss: 1.8439, Accuracy: 0.265625\n",
      "Epoch [36/100], Step [12/13],               Loss: 1.8212, Accuracy: 0.34375\n",
      "Epoch [36/100], Step [13/13],               Loss: 1.9552, Accuracy: 0.22580644488334656\n",
      "Epoch [37/100], Step [1/13],               Loss: 1.8580, Accuracy: 0.296875\n",
      "Epoch [37/100], Step [2/13],               Loss: 1.8108, Accuracy: 0.328125\n",
      "Epoch [37/100], Step [3/13],               Loss: 1.8052, Accuracy: 0.28125\n",
      "Epoch [37/100], Step [4/13],               Loss: 1.9495, Accuracy: 0.171875\n",
      "Epoch [37/100], Step [5/13],               Loss: 1.8688, Accuracy: 0.265625\n",
      "Epoch [37/100], Step [6/13],               Loss: 1.8662, Accuracy: 0.171875\n",
      "Epoch [37/100], Step [7/13],               Loss: 1.8261, Accuracy: 0.375\n",
      "Epoch [37/100], Step [8/13],               Loss: 1.7468, Accuracy: 0.421875\n",
      "Epoch [37/100], Step [9/13],               Loss: 1.9596, Accuracy: 0.171875\n",
      "Epoch [37/100], Step [10/13],               Loss: 1.8998, Accuracy: 0.265625\n",
      "Epoch [37/100], Step [11/13],               Loss: 1.7679, Accuracy: 0.3125\n",
      "Epoch [37/100], Step [12/13],               Loss: 1.8148, Accuracy: 0.1875\n",
      "Epoch [37/100], Step [13/13],               Loss: 1.8463, Accuracy: 0.35483869910240173\n",
      "Epoch [38/100], Step [1/13],               Loss: 1.8502, Accuracy: 0.28125\n",
      "Epoch [38/100], Step [2/13],               Loss: 1.9383, Accuracy: 0.1875\n",
      "Epoch [38/100], Step [3/13],               Loss: 1.8585, Accuracy: 0.234375\n",
      "Epoch [38/100], Step [4/13],               Loss: 1.8669, Accuracy: 0.21875\n",
      "Epoch [38/100], Step [5/13],               Loss: 1.8810, Accuracy: 0.28125\n",
      "Epoch [38/100], Step [6/13],               Loss: 1.8219, Accuracy: 0.296875\n",
      "Epoch [38/100], Step [7/13],               Loss: 1.7890, Accuracy: 0.3125\n",
      "Epoch [38/100], Step [8/13],               Loss: 1.7731, Accuracy: 0.421875\n",
      "Epoch [38/100], Step [9/13],               Loss: 1.8904, Accuracy: 0.265625\n",
      "Epoch [38/100], Step [10/13],               Loss: 1.8315, Accuracy: 0.28125\n",
      "Epoch [38/100], Step [11/13],               Loss: 1.8182, Accuracy: 0.25\n",
      "Epoch [38/100], Step [12/13],               Loss: 1.8900, Accuracy: 0.25\n",
      "Epoch [38/100], Step [13/13],               Loss: 1.8025, Accuracy: 0.29032257199287415\n",
      "Epoch [39/100], Step [1/13],               Loss: 1.7947, Accuracy: 0.3125\n",
      "Epoch [39/100], Step [2/13],               Loss: 1.8608, Accuracy: 0.265625\n",
      "Epoch [39/100], Step [3/13],               Loss: 1.7780, Accuracy: 0.34375\n",
      "Epoch [39/100], Step [4/13],               Loss: 1.8430, Accuracy: 0.25\n",
      "Epoch [39/100], Step [5/13],               Loss: 1.8756, Accuracy: 0.296875\n",
      "Epoch [39/100], Step [6/13],               Loss: 1.8253, Accuracy: 0.296875\n",
      "Epoch [39/100], Step [7/13],               Loss: 1.9433, Accuracy: 0.203125\n",
      "Epoch [39/100], Step [8/13],               Loss: 1.8124, Accuracy: 0.3125\n",
      "Epoch [39/100], Step [9/13],               Loss: 1.9323, Accuracy: 0.171875\n",
      "Epoch [39/100], Step [10/13],               Loss: 1.7992, Accuracy: 0.359375\n",
      "Epoch [39/100], Step [11/13],               Loss: 1.8326, Accuracy: 0.28125\n",
      "Epoch [39/100], Step [12/13],               Loss: 1.8888, Accuracy: 0.21875\n",
      "Epoch [39/100], Step [13/13],               Loss: 1.8143, Accuracy: 0.22580644488334656\n",
      "Epoch [40/100], Step [1/13],               Loss: 1.7676, Accuracy: 0.328125\n",
      "Epoch [40/100], Step [2/13],               Loss: 1.8558, Accuracy: 0.265625\n",
      "Epoch [40/100], Step [3/13],               Loss: 1.9132, Accuracy: 0.1875\n",
      "Epoch [40/100], Step [4/13],               Loss: 1.8731, Accuracy: 0.25\n",
      "Epoch [40/100], Step [5/13],               Loss: 1.8061, Accuracy: 0.328125\n",
      "Epoch [40/100], Step [6/13],               Loss: 1.8817, Accuracy: 0.25\n",
      "Epoch [40/100], Step [7/13],               Loss: 1.8769, Accuracy: 0.28125\n",
      "Epoch [40/100], Step [8/13],               Loss: 1.8535, Accuracy: 0.21875\n",
      "Epoch [40/100], Step [9/13],               Loss: 1.8556, Accuracy: 0.28125\n",
      "Epoch [40/100], Step [10/13],               Loss: 1.8056, Accuracy: 0.4375\n",
      "Epoch [40/100], Step [11/13],               Loss: 1.8710, Accuracy: 0.21875\n",
      "Epoch [40/100], Step [12/13],               Loss: 1.8869, Accuracy: 0.1875\n",
      "Epoch [40/100], Step [13/13],               Loss: 1.7609, Accuracy: 0.3870967626571655\n",
      "Epoch [41/100], Step [1/13],               Loss: 1.8261, Accuracy: 0.28125\n",
      "Epoch [41/100], Step [2/13],               Loss: 1.8268, Accuracy: 0.34375\n",
      "Epoch [41/100], Step [3/13],               Loss: 1.8432, Accuracy: 0.234375\n",
      "Epoch [41/100], Step [4/13],               Loss: 1.9273, Accuracy: 0.265625\n",
      "Epoch [41/100], Step [5/13],               Loss: 1.8888, Accuracy: 0.265625\n",
      "Epoch [41/100], Step [6/13],               Loss: 1.8213, Accuracy: 0.359375\n",
      "Epoch [41/100], Step [7/13],               Loss: 1.8128, Accuracy: 0.25\n",
      "Epoch [41/100], Step [8/13],               Loss: 1.8473, Accuracy: 0.25\n",
      "Epoch [41/100], Step [9/13],               Loss: 1.8432, Accuracy: 0.234375\n",
      "Epoch [41/100], Step [10/13],               Loss: 1.8951, Accuracy: 0.21875\n",
      "Epoch [41/100], Step [11/13],               Loss: 1.8681, Accuracy: 0.265625\n",
      "Epoch [41/100], Step [12/13],               Loss: 1.8499, Accuracy: 0.234375\n",
      "Epoch [41/100], Step [13/13],               Loss: 1.6847, Accuracy: 0.4516128897666931\n",
      "Epoch [42/100], Step [1/13],               Loss: 1.7266, Accuracy: 0.40625\n",
      "Epoch [42/100], Step [2/13],               Loss: 1.7473, Accuracy: 0.34375\n",
      "Epoch [42/100], Step [3/13],               Loss: 1.8711, Accuracy: 0.28125\n",
      "Epoch [42/100], Step [4/13],               Loss: 1.9675, Accuracy: 0.25\n",
      "Epoch [42/100], Step [5/13],               Loss: 2.0056, Accuracy: 0.15625\n",
      "Epoch [42/100], Step [6/13],               Loss: 1.8111, Accuracy: 0.296875\n",
      "Epoch [42/100], Step [7/13],               Loss: 1.8696, Accuracy: 0.28125\n",
      "Epoch [42/100], Step [8/13],               Loss: 1.8409, Accuracy: 0.34375\n",
      "Epoch [42/100], Step [9/13],               Loss: 1.8546, Accuracy: 0.34375\n",
      "Epoch [42/100], Step [10/13],               Loss: 1.9123, Accuracy: 0.15625\n",
      "Epoch [42/100], Step [11/13],               Loss: 1.8824, Accuracy: 0.25\n",
      "Epoch [42/100], Step [12/13],               Loss: 1.8998, Accuracy: 0.234375\n",
      "Epoch [42/100], Step [13/13],               Loss: 1.9448, Accuracy: 0.16129031777381897\n",
      "Epoch [43/100], Step [1/13],               Loss: 1.8729, Accuracy: 0.28125\n",
      "Epoch [43/100], Step [2/13],               Loss: 1.8779, Accuracy: 0.296875\n",
      "Epoch [43/100], Step [3/13],               Loss: 1.8767, Accuracy: 0.28125\n",
      "Epoch [43/100], Step [4/13],               Loss: 1.8470, Accuracy: 0.296875\n",
      "Epoch [43/100], Step [5/13],               Loss: 1.9095, Accuracy: 0.234375\n",
      "Epoch [43/100], Step [6/13],               Loss: 1.8335, Accuracy: 0.203125\n",
      "Epoch [43/100], Step [7/13],               Loss: 1.7014, Accuracy: 0.359375\n",
      "Epoch [43/100], Step [8/13],               Loss: 1.7576, Accuracy: 0.34375\n",
      "Epoch [43/100], Step [9/13],               Loss: 1.8544, Accuracy: 0.296875\n",
      "Epoch [43/100], Step [10/13],               Loss: 1.8517, Accuracy: 0.3125\n",
      "Epoch [43/100], Step [11/13],               Loss: 1.8695, Accuracy: 0.25\n",
      "Epoch [43/100], Step [12/13],               Loss: 1.8991, Accuracy: 0.15625\n",
      "Epoch [43/100], Step [13/13],               Loss: 1.9216, Accuracy: 0.22580644488334656\n",
      "Epoch [44/100], Step [1/13],               Loss: 1.8328, Accuracy: 0.265625\n",
      "Epoch [44/100], Step [2/13],               Loss: 1.8917, Accuracy: 0.203125\n",
      "Epoch [44/100], Step [3/13],               Loss: 1.8669, Accuracy: 0.203125\n",
      "Epoch [44/100], Step [4/13],               Loss: 1.7886, Accuracy: 0.40625\n",
      "Epoch [44/100], Step [5/13],               Loss: 1.8232, Accuracy: 0.296875\n",
      "Epoch [44/100], Step [6/13],               Loss: 1.8655, Accuracy: 0.296875\n",
      "Epoch [44/100], Step [7/13],               Loss: 1.8855, Accuracy: 0.25\n",
      "Epoch [44/100], Step [8/13],               Loss: 1.8757, Accuracy: 0.28125\n",
      "Epoch [44/100], Step [9/13],               Loss: 1.8608, Accuracy: 0.296875\n",
      "Epoch [44/100], Step [10/13],               Loss: 1.7950, Accuracy: 0.359375\n",
      "Epoch [44/100], Step [11/13],               Loss: 1.9107, Accuracy: 0.203125\n",
      "Epoch [44/100], Step [12/13],               Loss: 1.8420, Accuracy: 0.21875\n",
      "Epoch [44/100], Step [13/13],               Loss: 1.8192, Accuracy: 0.29032257199287415\n",
      "Epoch [45/100], Step [1/13],               Loss: 1.8215, Accuracy: 0.28125\n",
      "Epoch [45/100], Step [2/13],               Loss: 1.7173, Accuracy: 0.34375\n",
      "Epoch [45/100], Step [3/13],               Loss: 1.7377, Accuracy: 0.328125\n",
      "Epoch [45/100], Step [4/13],               Loss: 1.8724, Accuracy: 0.234375\n",
      "Epoch [45/100], Step [5/13],               Loss: 1.8383, Accuracy: 0.28125\n",
      "Epoch [45/100], Step [6/13],               Loss: 1.7715, Accuracy: 0.359375\n",
      "Epoch [45/100], Step [7/13],               Loss: 1.8721, Accuracy: 0.296875\n",
      "Epoch [45/100], Step [8/13],               Loss: 1.7703, Accuracy: 0.375\n",
      "Epoch [45/100], Step [9/13],               Loss: 1.9295, Accuracy: 0.15625\n",
      "Epoch [45/100], Step [10/13],               Loss: 1.8112, Accuracy: 0.234375\n",
      "Epoch [45/100], Step [11/13],               Loss: 1.8395, Accuracy: 0.3125\n",
      "Epoch [45/100], Step [12/13],               Loss: 1.7664, Accuracy: 0.375\n",
      "Epoch [45/100], Step [13/13],               Loss: 1.7809, Accuracy: 0.29032257199287415\n",
      "Epoch [46/100], Step [1/13],               Loss: 1.7998, Accuracy: 0.34375\n",
      "Epoch [46/100], Step [2/13],               Loss: 1.8313, Accuracy: 0.265625\n",
      "Epoch [46/100], Step [3/13],               Loss: 1.7460, Accuracy: 0.3125\n",
      "Epoch [46/100], Step [4/13],               Loss: 1.7016, Accuracy: 0.421875\n",
      "Epoch [46/100], Step [5/13],               Loss: 1.9322, Accuracy: 0.203125\n",
      "Epoch [46/100], Step [6/13],               Loss: 1.6954, Accuracy: 0.421875\n",
      "Epoch [46/100], Step [7/13],               Loss: 1.8904, Accuracy: 0.21875\n",
      "Epoch [46/100], Step [8/13],               Loss: 1.7096, Accuracy: 0.296875\n",
      "Epoch [46/100], Step [9/13],               Loss: 1.7000, Accuracy: 0.34375\n",
      "Epoch [46/100], Step [10/13],               Loss: 1.8713, Accuracy: 0.234375\n",
      "Epoch [46/100], Step [11/13],               Loss: 1.8154, Accuracy: 0.28125\n",
      "Epoch [46/100], Step [12/13],               Loss: 1.8264, Accuracy: 0.28125\n",
      "Epoch [46/100], Step [13/13],               Loss: 1.7642, Accuracy: 0.32258063554763794\n",
      "Epoch [47/100], Step [1/13],               Loss: 1.7032, Accuracy: 0.421875\n",
      "Epoch [47/100], Step [2/13],               Loss: 1.9005, Accuracy: 0.25\n",
      "Epoch [47/100], Step [3/13],               Loss: 1.6999, Accuracy: 0.421875\n",
      "Epoch [47/100], Step [4/13],               Loss: 1.7717, Accuracy: 0.265625\n",
      "Epoch [47/100], Step [5/13],               Loss: 1.6254, Accuracy: 0.421875\n",
      "Epoch [47/100], Step [6/13],               Loss: 1.6272, Accuracy: 0.375\n",
      "Epoch [47/100], Step [7/13],               Loss: 1.7475, Accuracy: 0.328125\n",
      "Epoch [47/100], Step [8/13],               Loss: 1.6937, Accuracy: 0.34375\n",
      "Epoch [47/100], Step [9/13],               Loss: 1.7545, Accuracy: 0.34375\n",
      "Epoch [47/100], Step [10/13],               Loss: 1.6441, Accuracy: 0.375\n",
      "Epoch [47/100], Step [11/13],               Loss: 1.6813, Accuracy: 0.3125\n",
      "Epoch [47/100], Step [12/13],               Loss: 1.5695, Accuracy: 0.484375\n",
      "Epoch [47/100], Step [13/13],               Loss: 1.4484, Accuracy: 0.4838709533214569\n",
      "Epoch [48/100], Step [1/13],               Loss: 1.5480, Accuracy: 0.390625\n",
      "Epoch [48/100], Step [2/13],               Loss: 1.6422, Accuracy: 0.40625\n",
      "Epoch [48/100], Step [3/13],               Loss: 1.5297, Accuracy: 0.375\n",
      "Epoch [48/100], Step [4/13],               Loss: 1.6103, Accuracy: 0.4375\n",
      "Epoch [48/100], Step [5/13],               Loss: 2.2059, Accuracy: 0.296875\n",
      "Epoch [48/100], Step [6/13],               Loss: 1.5755, Accuracy: 0.359375\n",
      "Epoch [48/100], Step [7/13],               Loss: 1.7007, Accuracy: 0.296875\n",
      "Epoch [48/100], Step [8/13],               Loss: 1.7978, Accuracy: 0.296875\n",
      "Epoch [48/100], Step [9/13],               Loss: 1.7999, Accuracy: 0.328125\n",
      "Epoch [48/100], Step [10/13],               Loss: 1.7893, Accuracy: 0.28125\n",
      "Epoch [48/100], Step [11/13],               Loss: 1.7646, Accuracy: 0.390625\n",
      "Epoch [48/100], Step [12/13],               Loss: 1.7959, Accuracy: 0.3125\n",
      "Epoch [48/100], Step [13/13],               Loss: 1.7330, Accuracy: 0.25806450843811035\n",
      "Epoch [49/100], Step [1/13],               Loss: 1.8151, Accuracy: 0.234375\n",
      "Epoch [49/100], Step [2/13],               Loss: 1.6679, Accuracy: 0.328125\n",
      "Epoch [49/100], Step [3/13],               Loss: 1.6993, Accuracy: 0.40625\n",
      "Epoch [49/100], Step [4/13],               Loss: 1.7712, Accuracy: 0.34375\n",
      "Epoch [49/100], Step [5/13],               Loss: 1.8192, Accuracy: 0.28125\n",
      "Epoch [49/100], Step [6/13],               Loss: 1.5929, Accuracy: 0.40625\n",
      "Epoch [49/100], Step [7/13],               Loss: 1.8021, Accuracy: 0.359375\n",
      "Epoch [49/100], Step [8/13],               Loss: 1.6951, Accuracy: 0.421875\n",
      "Epoch [49/100], Step [9/13],               Loss: 1.6242, Accuracy: 0.421875\n",
      "Epoch [49/100], Step [10/13],               Loss: 1.7775, Accuracy: 0.359375\n",
      "Epoch [49/100], Step [11/13],               Loss: 1.7264, Accuracy: 0.34375\n",
      "Epoch [49/100], Step [12/13],               Loss: 1.5237, Accuracy: 0.453125\n",
      "Epoch [49/100], Step [13/13],               Loss: 1.9891, Accuracy: 0.19354838132858276\n",
      "Epoch [50/100], Step [1/13],               Loss: 1.8021, Accuracy: 0.296875\n",
      "Epoch [50/100], Step [2/13],               Loss: 1.6309, Accuracy: 0.5\n",
      "Epoch [50/100], Step [3/13],               Loss: 1.6091, Accuracy: 0.3125\n",
      "Epoch [50/100], Step [4/13],               Loss: 1.6674, Accuracy: 0.390625\n",
      "Epoch [50/100], Step [5/13],               Loss: 1.5916, Accuracy: 0.375\n",
      "Epoch [50/100], Step [6/13],               Loss: 1.6580, Accuracy: 0.21875\n",
      "Epoch [50/100], Step [7/13],               Loss: 1.5473, Accuracy: 0.421875\n",
      "Epoch [50/100], Step [8/13],               Loss: 1.7614, Accuracy: 0.328125\n",
      "Epoch [50/100], Step [9/13],               Loss: 1.4581, Accuracy: 0.5625\n",
      "Epoch [50/100], Step [10/13],               Loss: 1.4370, Accuracy: 0.40625\n",
      "Epoch [50/100], Step [11/13],               Loss: 1.7332, Accuracy: 0.359375\n",
      "Epoch [50/100], Step [12/13],               Loss: 1.4828, Accuracy: 0.453125\n",
      "Epoch [50/100], Step [13/13],               Loss: 1.6717, Accuracy: 0.4193548262119293\n",
      "Epoch [51/100], Step [1/13],               Loss: 1.4714, Accuracy: 0.390625\n",
      "Epoch [51/100], Step [2/13],               Loss: 1.4607, Accuracy: 0.453125\n",
      "Epoch [51/100], Step [3/13],               Loss: 1.6232, Accuracy: 0.375\n",
      "Epoch [51/100], Step [4/13],               Loss: 1.6012, Accuracy: 0.296875\n",
      "Epoch [51/100], Step [5/13],               Loss: 1.3857, Accuracy: 0.453125\n",
      "Epoch [51/100], Step [6/13],               Loss: 1.4792, Accuracy: 0.421875\n",
      "Epoch [51/100], Step [7/13],               Loss: 1.3375, Accuracy: 0.5\n",
      "Epoch [51/100], Step [8/13],               Loss: 1.5165, Accuracy: 0.4375\n",
      "Epoch [51/100], Step [9/13],               Loss: 1.6274, Accuracy: 0.359375\n",
      "Epoch [51/100], Step [10/13],               Loss: 1.6242, Accuracy: 0.390625\n",
      "Epoch [51/100], Step [11/13],               Loss: 1.5891, Accuracy: 0.359375\n",
      "Epoch [51/100], Step [12/13],               Loss: 1.5948, Accuracy: 0.421875\n",
      "Epoch [51/100], Step [13/13],               Loss: 1.6999, Accuracy: 0.32258063554763794\n",
      "Epoch [52/100], Step [1/13],               Loss: 1.4494, Accuracy: 0.4375\n",
      "Epoch [52/100], Step [2/13],               Loss: 1.6311, Accuracy: 0.359375\n",
      "Epoch [52/100], Step [3/13],               Loss: 1.5023, Accuracy: 0.421875\n",
      "Epoch [52/100], Step [4/13],               Loss: 1.4600, Accuracy: 0.390625\n",
      "Epoch [52/100], Step [5/13],               Loss: 1.3670, Accuracy: 0.515625\n",
      "Epoch [52/100], Step [6/13],               Loss: 1.4838, Accuracy: 0.390625\n",
      "Epoch [52/100], Step [7/13],               Loss: 1.3592, Accuracy: 0.5\n",
      "Epoch [52/100], Step [8/13],               Loss: 1.7502, Accuracy: 0.390625\n",
      "Epoch [52/100], Step [9/13],               Loss: 1.3227, Accuracy: 0.515625\n",
      "Epoch [52/100], Step [10/13],               Loss: 1.3805, Accuracy: 0.421875\n",
      "Epoch [52/100], Step [11/13],               Loss: 1.7291, Accuracy: 0.359375\n",
      "Epoch [52/100], Step [12/13],               Loss: 1.6153, Accuracy: 0.390625\n",
      "Epoch [52/100], Step [13/13],               Loss: 1.5833, Accuracy: 0.35483869910240173\n",
      "Epoch [53/100], Step [1/13],               Loss: 1.5183, Accuracy: 0.4375\n",
      "Epoch [53/100], Step [2/13],               Loss: 1.6306, Accuracy: 0.359375\n",
      "Epoch [53/100], Step [3/13],               Loss: 1.5664, Accuracy: 0.390625\n",
      "Epoch [53/100], Step [4/13],               Loss: 1.5252, Accuracy: 0.421875\n",
      "Epoch [53/100], Step [5/13],               Loss: 1.5458, Accuracy: 0.40625\n",
      "Epoch [53/100], Step [6/13],               Loss: 1.4824, Accuracy: 0.4375\n",
      "Epoch [53/100], Step [7/13],               Loss: 1.6229, Accuracy: 0.375\n",
      "Epoch [53/100], Step [8/13],               Loss: 1.4648, Accuracy: 0.390625\n",
      "Epoch [53/100], Step [9/13],               Loss: 1.4863, Accuracy: 0.453125\n",
      "Epoch [53/100], Step [10/13],               Loss: 1.5569, Accuracy: 0.40625\n",
      "Epoch [53/100], Step [11/13],               Loss: 1.3413, Accuracy: 0.5\n",
      "Epoch [53/100], Step [12/13],               Loss: 1.5875, Accuracy: 0.40625\n",
      "Epoch [53/100], Step [13/13],               Loss: 1.5678, Accuracy: 0.4193548262119293\n",
      "Epoch [54/100], Step [1/13],               Loss: 1.5569, Accuracy: 0.390625\n",
      "Epoch [54/100], Step [2/13],               Loss: 1.5563, Accuracy: 0.375\n",
      "Epoch [54/100], Step [3/13],               Loss: 1.2832, Accuracy: 0.484375\n",
      "Epoch [54/100], Step [4/13],               Loss: 1.4128, Accuracy: 0.484375\n",
      "Epoch [54/100], Step [5/13],               Loss: 1.5390, Accuracy: 0.390625\n",
      "Epoch [54/100], Step [6/13],               Loss: 1.3591, Accuracy: 0.421875\n",
      "Epoch [54/100], Step [7/13],               Loss: 1.3331, Accuracy: 0.5\n",
      "Epoch [54/100], Step [8/13],               Loss: 1.6430, Accuracy: 0.359375\n",
      "Epoch [54/100], Step [9/13],               Loss: 1.1860, Accuracy: 0.453125\n",
      "Epoch [54/100], Step [10/13],               Loss: 1.5623, Accuracy: 0.3125\n",
      "Epoch [54/100], Step [11/13],               Loss: 1.4594, Accuracy: 0.40625\n",
      "Epoch [54/100], Step [12/13],               Loss: 1.7073, Accuracy: 0.328125\n",
      "Epoch [54/100], Step [13/13],               Loss: 1.7513, Accuracy: 0.32258063554763794\n",
      "Epoch [55/100], Step [1/13],               Loss: 1.4841, Accuracy: 0.515625\n",
      "Epoch [55/100], Step [2/13],               Loss: 1.4689, Accuracy: 0.46875\n",
      "Epoch [55/100], Step [3/13],               Loss: 1.4576, Accuracy: 0.421875\n",
      "Epoch [55/100], Step [4/13],               Loss: 1.3308, Accuracy: 0.484375\n",
      "Epoch [55/100], Step [5/13],               Loss: 1.3236, Accuracy: 0.5\n",
      "Epoch [55/100], Step [6/13],               Loss: 1.4910, Accuracy: 0.421875\n",
      "Epoch [55/100], Step [7/13],               Loss: 1.3497, Accuracy: 0.515625\n",
      "Epoch [55/100], Step [8/13],               Loss: 1.4802, Accuracy: 0.390625\n",
      "Epoch [55/100], Step [9/13],               Loss: 1.5187, Accuracy: 0.375\n",
      "Epoch [55/100], Step [10/13],               Loss: 1.3803, Accuracy: 0.515625\n",
      "Epoch [55/100], Step [11/13],               Loss: 1.2881, Accuracy: 0.46875\n",
      "Epoch [55/100], Step [12/13],               Loss: 1.5843, Accuracy: 0.296875\n",
      "Epoch [55/100], Step [13/13],               Loss: 1.3864, Accuracy: 0.5161290168762207\n",
      "Epoch [56/100], Step [1/13],               Loss: 1.3650, Accuracy: 0.421875\n",
      "Epoch [56/100], Step [2/13],               Loss: 1.5048, Accuracy: 0.484375\n",
      "Epoch [56/100], Step [3/13],               Loss: 1.3686, Accuracy: 0.546875\n",
      "Epoch [56/100], Step [4/13],               Loss: 1.4761, Accuracy: 0.34375\n",
      "Epoch [56/100], Step [5/13],               Loss: 1.2834, Accuracy: 0.484375\n",
      "Epoch [56/100], Step [6/13],               Loss: 1.6256, Accuracy: 0.359375\n",
      "Epoch [56/100], Step [7/13],               Loss: 1.3624, Accuracy: 0.421875\n",
      "Epoch [56/100], Step [8/13],               Loss: 1.4603, Accuracy: 0.40625\n",
      "Epoch [56/100], Step [9/13],               Loss: 1.4210, Accuracy: 0.421875\n",
      "Epoch [56/100], Step [10/13],               Loss: 1.1671, Accuracy: 0.65625\n",
      "Epoch [56/100], Step [11/13],               Loss: 1.3219, Accuracy: 0.5\n",
      "Epoch [56/100], Step [12/13],               Loss: 1.4567, Accuracy: 0.390625\n",
      "Epoch [56/100], Step [13/13],               Loss: 1.3800, Accuracy: 0.35483869910240173\n",
      "Epoch [57/100], Step [1/13],               Loss: 1.3514, Accuracy: 0.578125\n",
      "Epoch [57/100], Step [2/13],               Loss: 1.3597, Accuracy: 0.5\n",
      "Epoch [57/100], Step [3/13],               Loss: 1.3270, Accuracy: 0.421875\n",
      "Epoch [57/100], Step [4/13],               Loss: 1.3698, Accuracy: 0.421875\n",
      "Epoch [57/100], Step [5/13],               Loss: 1.1298, Accuracy: 0.5625\n",
      "Epoch [57/100], Step [6/13],               Loss: 1.2609, Accuracy: 0.4375\n",
      "Epoch [57/100], Step [7/13],               Loss: 1.4334, Accuracy: 0.46875\n",
      "Epoch [57/100], Step [8/13],               Loss: 1.3102, Accuracy: 0.5\n",
      "Epoch [57/100], Step [9/13],               Loss: 1.2738, Accuracy: 0.53125\n",
      "Epoch [57/100], Step [10/13],               Loss: 1.4107, Accuracy: 0.375\n",
      "Epoch [57/100], Step [11/13],               Loss: 1.4028, Accuracy: 0.4375\n",
      "Epoch [57/100], Step [12/13],               Loss: 1.2589, Accuracy: 0.53125\n",
      "Epoch [57/100], Step [13/13],               Loss: 1.3901, Accuracy: 0.4838709533214569\n",
      "Epoch [58/100], Step [1/13],               Loss: 1.3572, Accuracy: 0.484375\n",
      "Epoch [58/100], Step [2/13],               Loss: 1.4531, Accuracy: 0.4375\n",
      "Epoch [58/100], Step [3/13],               Loss: 1.4106, Accuracy: 0.46875\n",
      "Epoch [58/100], Step [4/13],               Loss: 1.3697, Accuracy: 0.453125\n",
      "Epoch [58/100], Step [5/13],               Loss: 1.2054, Accuracy: 0.5\n",
      "Epoch [58/100], Step [6/13],               Loss: 1.3447, Accuracy: 0.484375\n",
      "Epoch [58/100], Step [7/13],               Loss: 1.4054, Accuracy: 0.484375\n",
      "Epoch [58/100], Step [8/13],               Loss: 1.2815, Accuracy: 0.453125\n",
      "Epoch [58/100], Step [9/13],               Loss: 1.3801, Accuracy: 0.4375\n",
      "Epoch [58/100], Step [10/13],               Loss: 1.0647, Accuracy: 0.578125\n",
      "Epoch [58/100], Step [11/13],               Loss: 1.1492, Accuracy: 0.59375\n",
      "Epoch [58/100], Step [12/13],               Loss: 1.2483, Accuracy: 0.5\n",
      "Epoch [58/100], Step [13/13],               Loss: 1.1414, Accuracy: 0.6774193644523621\n",
      "Epoch [59/100], Step [1/13],               Loss: 1.3852, Accuracy: 0.421875\n",
      "Epoch [59/100], Step [2/13],               Loss: 1.3638, Accuracy: 0.4375\n",
      "Epoch [59/100], Step [3/13],               Loss: 1.3651, Accuracy: 0.5\n",
      "Epoch [59/100], Step [4/13],               Loss: 1.1474, Accuracy: 0.546875\n",
      "Epoch [59/100], Step [5/13],               Loss: 1.1902, Accuracy: 0.546875\n",
      "Epoch [59/100], Step [6/13],               Loss: 1.4607, Accuracy: 0.390625\n",
      "Epoch [59/100], Step [7/13],               Loss: 1.4488, Accuracy: 0.4375\n",
      "Epoch [59/100], Step [8/13],               Loss: 1.1811, Accuracy: 0.546875\n",
      "Epoch [59/100], Step [9/13],               Loss: 1.3033, Accuracy: 0.4375\n",
      "Epoch [59/100], Step [10/13],               Loss: 1.2007, Accuracy: 0.625\n",
      "Epoch [59/100], Step [11/13],               Loss: 1.2594, Accuracy: 0.546875\n",
      "Epoch [59/100], Step [12/13],               Loss: 1.2391, Accuracy: 0.53125\n",
      "Epoch [59/100], Step [13/13],               Loss: 1.1785, Accuracy: 0.5161290168762207\n",
      "Epoch [60/100], Step [1/13],               Loss: 1.2991, Accuracy: 0.46875\n",
      "Epoch [60/100], Step [2/13],               Loss: 1.1440, Accuracy: 0.5625\n",
      "Epoch [60/100], Step [3/13],               Loss: 1.2038, Accuracy: 0.546875\n",
      "Epoch [60/100], Step [4/13],               Loss: 1.1120, Accuracy: 0.515625\n",
      "Epoch [60/100], Step [5/13],               Loss: 1.1533, Accuracy: 0.625\n",
      "Epoch [60/100], Step [6/13],               Loss: 1.0820, Accuracy: 0.5625\n",
      "Epoch [60/100], Step [7/13],               Loss: 1.1105, Accuracy: 0.546875\n",
      "Epoch [60/100], Step [8/13],               Loss: 1.4029, Accuracy: 0.46875\n",
      "Epoch [60/100], Step [9/13],               Loss: 1.0474, Accuracy: 0.625\n",
      "Epoch [60/100], Step [10/13],               Loss: 1.3200, Accuracy: 0.453125\n",
      "Epoch [60/100], Step [11/13],               Loss: 1.2789, Accuracy: 0.5625\n",
      "Epoch [60/100], Step [12/13],               Loss: 1.1200, Accuracy: 0.578125\n",
      "Epoch [60/100], Step [13/13],               Loss: 1.4751, Accuracy: 0.3870967626571655\n",
      "Epoch [61/100], Step [1/13],               Loss: 1.3372, Accuracy: 0.515625\n",
      "Epoch [61/100], Step [2/13],               Loss: 1.2805, Accuracy: 0.515625\n",
      "Epoch [61/100], Step [3/13],               Loss: 0.9976, Accuracy: 0.578125\n",
      "Epoch [61/100], Step [4/13],               Loss: 1.0930, Accuracy: 0.53125\n",
      "Epoch [61/100], Step [5/13],               Loss: 1.4596, Accuracy: 0.46875\n",
      "Epoch [61/100], Step [6/13],               Loss: 1.0588, Accuracy: 0.578125\n",
      "Epoch [61/100], Step [7/13],               Loss: 1.1821, Accuracy: 0.578125\n",
      "Epoch [61/100], Step [8/13],               Loss: 1.0319, Accuracy: 0.640625\n",
      "Epoch [61/100], Step [9/13],               Loss: 1.2501, Accuracy: 0.484375\n",
      "Epoch [61/100], Step [10/13],               Loss: 1.0561, Accuracy: 0.5625\n",
      "Epoch [61/100], Step [11/13],               Loss: 1.1427, Accuracy: 0.59375\n",
      "Epoch [61/100], Step [12/13],               Loss: 1.1789, Accuracy: 0.53125\n",
      "Epoch [61/100], Step [13/13],               Loss: 1.0986, Accuracy: 0.5483871102333069\n",
      "Epoch [62/100], Step [1/13],               Loss: 0.9982, Accuracy: 0.5625\n",
      "Epoch [62/100], Step [2/13],               Loss: 1.0439, Accuracy: 0.640625\n",
      "Epoch [62/100], Step [3/13],               Loss: 0.9954, Accuracy: 0.671875\n",
      "Epoch [62/100], Step [4/13],               Loss: 1.0224, Accuracy: 0.59375\n",
      "Epoch [62/100], Step [5/13],               Loss: 1.2961, Accuracy: 0.59375\n",
      "Epoch [62/100], Step [6/13],               Loss: 1.1854, Accuracy: 0.53125\n",
      "Epoch [62/100], Step [7/13],               Loss: 1.2475, Accuracy: 0.53125\n",
      "Epoch [62/100], Step [8/13],               Loss: 1.2604, Accuracy: 0.515625\n",
      "Epoch [62/100], Step [9/13],               Loss: 1.1452, Accuracy: 0.625\n",
      "Epoch [62/100], Step [10/13],               Loss: 1.0884, Accuracy: 0.671875\n",
      "Epoch [62/100], Step [11/13],               Loss: 1.3740, Accuracy: 0.484375\n",
      "Epoch [62/100], Step [12/13],               Loss: 1.2448, Accuracy: 0.53125\n",
      "Epoch [62/100], Step [13/13],               Loss: 1.4308, Accuracy: 0.35483869910240173\n",
      "Epoch [63/100], Step [1/13],               Loss: 0.9711, Accuracy: 0.578125\n",
      "Epoch [63/100], Step [2/13],               Loss: 1.1656, Accuracy: 0.5\n",
      "Epoch [63/100], Step [3/13],               Loss: 1.0924, Accuracy: 0.5625\n",
      "Epoch [63/100], Step [4/13],               Loss: 1.1578, Accuracy: 0.5625\n",
      "Epoch [63/100], Step [5/13],               Loss: 1.3686, Accuracy: 0.453125\n",
      "Epoch [63/100], Step [6/13],               Loss: 1.1066, Accuracy: 0.578125\n",
      "Epoch [63/100], Step [7/13],               Loss: 1.1835, Accuracy: 0.609375\n",
      "Epoch [63/100], Step [8/13],               Loss: 1.2025, Accuracy: 0.546875\n",
      "Epoch [63/100], Step [9/13],               Loss: 1.1226, Accuracy: 0.53125\n",
      "Epoch [63/100], Step [10/13],               Loss: 1.2970, Accuracy: 0.5\n",
      "Epoch [63/100], Step [11/13],               Loss: 0.9407, Accuracy: 0.609375\n",
      "Epoch [63/100], Step [12/13],               Loss: 1.1916, Accuracy: 0.53125\n",
      "Epoch [63/100], Step [13/13],               Loss: 1.2220, Accuracy: 0.5161290168762207\n",
      "Epoch [64/100], Step [1/13],               Loss: 0.9407, Accuracy: 0.65625\n",
      "Epoch [64/100], Step [2/13],               Loss: 1.2470, Accuracy: 0.40625\n",
      "Epoch [64/100], Step [3/13],               Loss: 1.0955, Accuracy: 0.609375\n",
      "Epoch [64/100], Step [4/13],               Loss: 1.0366, Accuracy: 0.609375\n",
      "Epoch [64/100], Step [5/13],               Loss: 1.3803, Accuracy: 0.4375\n",
      "Epoch [64/100], Step [6/13],               Loss: 1.3598, Accuracy: 0.515625\n",
      "Epoch [64/100], Step [7/13],               Loss: 1.0862, Accuracy: 0.515625\n",
      "Epoch [64/100], Step [8/13],               Loss: 1.1585, Accuracy: 0.5\n",
      "Epoch [64/100], Step [9/13],               Loss: 0.9854, Accuracy: 0.59375\n",
      "Epoch [64/100], Step [10/13],               Loss: 1.1757, Accuracy: 0.5\n",
      "Epoch [64/100], Step [11/13],               Loss: 0.9807, Accuracy: 0.65625\n",
      "Epoch [64/100], Step [12/13],               Loss: 0.9343, Accuracy: 0.703125\n",
      "Epoch [64/100], Step [13/13],               Loss: 1.0959, Accuracy: 0.4516128897666931\n",
      "Epoch [65/100], Step [1/13],               Loss: 1.0994, Accuracy: 0.609375\n",
      "Epoch [65/100], Step [2/13],               Loss: 1.0049, Accuracy: 0.671875\n",
      "Epoch [65/100], Step [3/13],               Loss: 0.9196, Accuracy: 0.5625\n",
      "Epoch [65/100], Step [4/13],               Loss: 0.9223, Accuracy: 0.65625\n",
      "Epoch [65/100], Step [5/13],               Loss: 1.3066, Accuracy: 0.5\n",
      "Epoch [65/100], Step [6/13],               Loss: 1.0066, Accuracy: 0.671875\n",
      "Epoch [65/100], Step [7/13],               Loss: 1.0661, Accuracy: 0.59375\n",
      "Epoch [65/100], Step [8/13],               Loss: 0.9247, Accuracy: 0.625\n",
      "Epoch [65/100], Step [9/13],               Loss: 1.1038, Accuracy: 0.640625\n",
      "Epoch [65/100], Step [10/13],               Loss: 0.9395, Accuracy: 0.625\n",
      "Epoch [65/100], Step [11/13],               Loss: 1.0614, Accuracy: 0.59375\n",
      "Epoch [65/100], Step [12/13],               Loss: 1.1632, Accuracy: 0.453125\n",
      "Epoch [65/100], Step [13/13],               Loss: 0.8833, Accuracy: 0.6774193644523621\n",
      "Epoch [66/100], Step [1/13],               Loss: 0.9166, Accuracy: 0.6875\n",
      "Epoch [66/100], Step [2/13],               Loss: 1.1455, Accuracy: 0.5625\n",
      "Epoch [66/100], Step [3/13],               Loss: 0.9169, Accuracy: 0.703125\n",
      "Epoch [66/100], Step [4/13],               Loss: 0.8785, Accuracy: 0.65625\n",
      "Epoch [66/100], Step [5/13],               Loss: 0.9125, Accuracy: 0.703125\n",
      "Epoch [66/100], Step [6/13],               Loss: 0.8531, Accuracy: 0.640625\n",
      "Epoch [66/100], Step [7/13],               Loss: 1.1518, Accuracy: 0.515625\n",
      "Epoch [66/100], Step [8/13],               Loss: 0.9631, Accuracy: 0.671875\n",
      "Epoch [66/100], Step [9/13],               Loss: 1.0505, Accuracy: 0.5625\n",
      "Epoch [66/100], Step [10/13],               Loss: 0.8073, Accuracy: 0.703125\n",
      "Epoch [66/100], Step [11/13],               Loss: 0.9642, Accuracy: 0.625\n",
      "Epoch [66/100], Step [12/13],               Loss: 0.7901, Accuracy: 0.6875\n",
      "Epoch [66/100], Step [13/13],               Loss: 1.0875, Accuracy: 0.4838709533214569\n",
      "Epoch [67/100], Step [1/13],               Loss: 0.9666, Accuracy: 0.609375\n",
      "Epoch [67/100], Step [2/13],               Loss: 0.9041, Accuracy: 0.640625\n",
      "Epoch [67/100], Step [3/13],               Loss: 0.8717, Accuracy: 0.765625\n",
      "Epoch [67/100], Step [4/13],               Loss: 0.6754, Accuracy: 0.765625\n",
      "Epoch [67/100], Step [5/13],               Loss: 0.7316, Accuracy: 0.703125\n",
      "Epoch [67/100], Step [6/13],               Loss: 0.8470, Accuracy: 0.71875\n",
      "Epoch [67/100], Step [7/13],               Loss: 1.1251, Accuracy: 0.609375\n",
      "Epoch [67/100], Step [8/13],               Loss: 1.0577, Accuracy: 0.671875\n",
      "Epoch [67/100], Step [9/13],               Loss: 1.2031, Accuracy: 0.515625\n",
      "Epoch [67/100], Step [10/13],               Loss: 1.1029, Accuracy: 0.53125\n",
      "Epoch [67/100], Step [11/13],               Loss: 1.2892, Accuracy: 0.484375\n",
      "Epoch [67/100], Step [12/13],               Loss: 1.2108, Accuracy: 0.546875\n",
      "Epoch [67/100], Step [13/13],               Loss: 1.1537, Accuracy: 0.5806451439857483\n",
      "Epoch [68/100], Step [1/13],               Loss: 0.9280, Accuracy: 0.703125\n",
      "Epoch [68/100], Step [2/13],               Loss: 0.9984, Accuracy: 0.578125\n",
      "Epoch [68/100], Step [3/13],               Loss: 0.9890, Accuracy: 0.515625\n",
      "Epoch [68/100], Step [4/13],               Loss: 1.1164, Accuracy: 0.515625\n",
      "Epoch [68/100], Step [5/13],               Loss: 1.0190, Accuracy: 0.59375\n",
      "Epoch [68/100], Step [6/13],               Loss: 1.0827, Accuracy: 0.671875\n",
      "Epoch [68/100], Step [7/13],               Loss: 0.8703, Accuracy: 0.765625\n",
      "Epoch [68/100], Step [8/13],               Loss: 0.9962, Accuracy: 0.625\n",
      "Epoch [68/100], Step [9/13],               Loss: 0.9289, Accuracy: 0.59375\n",
      "Epoch [68/100], Step [10/13],               Loss: 1.0553, Accuracy: 0.546875\n",
      "Epoch [68/100], Step [11/13],               Loss: 0.9717, Accuracy: 0.625\n",
      "Epoch [68/100], Step [12/13],               Loss: 0.9930, Accuracy: 0.5625\n",
      "Epoch [68/100], Step [13/13],               Loss: 0.8774, Accuracy: 0.5806451439857483\n",
      "Epoch [69/100], Step [1/13],               Loss: 0.7355, Accuracy: 0.6875\n",
      "Epoch [69/100], Step [2/13],               Loss: 1.1467, Accuracy: 0.609375\n",
      "Epoch [69/100], Step [3/13],               Loss: 1.2929, Accuracy: 0.53125\n",
      "Epoch [69/100], Step [4/13],               Loss: 1.1178, Accuracy: 0.625\n",
      "Epoch [69/100], Step [5/13],               Loss: 0.9913, Accuracy: 0.65625\n",
      "Epoch [69/100], Step [6/13],               Loss: 0.9401, Accuracy: 0.6875\n",
      "Epoch [69/100], Step [7/13],               Loss: 1.1784, Accuracy: 0.609375\n",
      "Epoch [69/100], Step [8/13],               Loss: 0.8312, Accuracy: 0.6875\n",
      "Epoch [69/100], Step [9/13],               Loss: 1.3334, Accuracy: 0.5\n",
      "Epoch [69/100], Step [10/13],               Loss: 1.0879, Accuracy: 0.625\n",
      "Epoch [69/100], Step [11/13],               Loss: 1.1594, Accuracy: 0.53125\n",
      "Epoch [69/100], Step [12/13],               Loss: 1.1184, Accuracy: 0.578125\n",
      "Epoch [69/100], Step [13/13],               Loss: 1.1815, Accuracy: 0.6451612710952759\n",
      "Epoch [70/100], Step [1/13],               Loss: 1.0259, Accuracy: 0.578125\n",
      "Epoch [70/100], Step [2/13],               Loss: 1.1311, Accuracy: 0.59375\n",
      "Epoch [70/100], Step [3/13],               Loss: 0.7804, Accuracy: 0.734375\n",
      "Epoch [70/100], Step [4/13],               Loss: 0.9414, Accuracy: 0.625\n",
      "Epoch [70/100], Step [5/13],               Loss: 0.9013, Accuracy: 0.671875\n",
      "Epoch [70/100], Step [6/13],               Loss: 0.9779, Accuracy: 0.625\n",
      "Epoch [70/100], Step [7/13],               Loss: 1.1357, Accuracy: 0.609375\n",
      "Epoch [70/100], Step [8/13],               Loss: 0.9017, Accuracy: 0.625\n",
      "Epoch [70/100], Step [9/13],               Loss: 0.8503, Accuracy: 0.59375\n",
      "Epoch [70/100], Step [10/13],               Loss: 1.0289, Accuracy: 0.609375\n",
      "Epoch [70/100], Step [11/13],               Loss: 0.8295, Accuracy: 0.734375\n",
      "Epoch [70/100], Step [12/13],               Loss: 0.8347, Accuracy: 0.6875\n",
      "Epoch [70/100], Step [13/13],               Loss: 1.0203, Accuracy: 0.5483871102333069\n",
      "Epoch [71/100], Step [1/13],               Loss: 0.7495, Accuracy: 0.703125\n",
      "Epoch [71/100], Step [2/13],               Loss: 0.8161, Accuracy: 0.703125\n",
      "Epoch [71/100], Step [3/13],               Loss: 0.6662, Accuracy: 0.703125\n",
      "Epoch [71/100], Step [4/13],               Loss: 0.9593, Accuracy: 0.65625\n",
      "Epoch [71/100], Step [5/13],               Loss: 0.8286, Accuracy: 0.6875\n",
      "Epoch [71/100], Step [6/13],               Loss: 0.9189, Accuracy: 0.734375\n",
      "Epoch [71/100], Step [7/13],               Loss: 0.8406, Accuracy: 0.71875\n",
      "Epoch [71/100], Step [8/13],               Loss: 0.7359, Accuracy: 0.734375\n",
      "Epoch [71/100], Step [9/13],               Loss: 0.9792, Accuracy: 0.59375\n",
      "Epoch [71/100], Step [10/13],               Loss: 0.8857, Accuracy: 0.65625\n",
      "Epoch [71/100], Step [11/13],               Loss: 0.8887, Accuracy: 0.609375\n",
      "Epoch [71/100], Step [12/13],               Loss: 1.1231, Accuracy: 0.546875\n",
      "Epoch [71/100], Step [13/13],               Loss: 0.7879, Accuracy: 0.6451612710952759\n",
      "Epoch [72/100], Step [1/13],               Loss: 0.7596, Accuracy: 0.703125\n",
      "Epoch [72/100], Step [2/13],               Loss: 0.8105, Accuracy: 0.703125\n",
      "Epoch [72/100], Step [3/13],               Loss: 0.9766, Accuracy: 0.625\n",
      "Epoch [72/100], Step [4/13],               Loss: 1.0553, Accuracy: 0.546875\n",
      "Epoch [72/100], Step [5/13],               Loss: 1.0562, Accuracy: 0.59375\n",
      "Epoch [72/100], Step [6/13],               Loss: 0.8191, Accuracy: 0.703125\n",
      "Epoch [72/100], Step [7/13],               Loss: 1.1364, Accuracy: 0.578125\n",
      "Epoch [72/100], Step [8/13],               Loss: 0.8987, Accuracy: 0.640625\n",
      "Epoch [72/100], Step [9/13],               Loss: 1.0163, Accuracy: 0.609375\n",
      "Epoch [72/100], Step [10/13],               Loss: 0.9617, Accuracy: 0.640625\n",
      "Epoch [72/100], Step [11/13],               Loss: 1.0689, Accuracy: 0.609375\n",
      "Epoch [72/100], Step [12/13],               Loss: 0.9871, Accuracy: 0.609375\n",
      "Epoch [72/100], Step [13/13],               Loss: 1.0114, Accuracy: 0.6774193644523621\n",
      "Epoch [73/100], Step [1/13],               Loss: 0.9555, Accuracy: 0.640625\n",
      "Epoch [73/100], Step [2/13],               Loss: 0.7218, Accuracy: 0.75\n",
      "Epoch [73/100], Step [3/13],               Loss: 0.7474, Accuracy: 0.765625\n",
      "Epoch [73/100], Step [4/13],               Loss: 0.6225, Accuracy: 0.75\n",
      "Epoch [73/100], Step [5/13],               Loss: 0.8049, Accuracy: 0.671875\n",
      "Epoch [73/100], Step [6/13],               Loss: 1.0556, Accuracy: 0.59375\n",
      "Epoch [73/100], Step [7/13],               Loss: 0.9917, Accuracy: 0.609375\n",
      "Epoch [73/100], Step [8/13],               Loss: 0.6731, Accuracy: 0.71875\n",
      "Epoch [73/100], Step [9/13],               Loss: 0.7973, Accuracy: 0.703125\n",
      "Epoch [73/100], Step [10/13],               Loss: 0.8056, Accuracy: 0.6875\n",
      "Epoch [73/100], Step [11/13],               Loss: 0.7253, Accuracy: 0.75\n",
      "Epoch [73/100], Step [12/13],               Loss: 1.1538, Accuracy: 0.546875\n",
      "Epoch [73/100], Step [13/13],               Loss: 0.9298, Accuracy: 0.5483871102333069\n",
      "Epoch [74/100], Step [1/13],               Loss: 0.7962, Accuracy: 0.6875\n",
      "Epoch [74/100], Step [2/13],               Loss: 0.7649, Accuracy: 0.71875\n",
      "Epoch [74/100], Step [3/13],               Loss: 1.0019, Accuracy: 0.65625\n",
      "Epoch [74/100], Step [4/13],               Loss: 0.6513, Accuracy: 0.734375\n",
      "Epoch [74/100], Step [5/13],               Loss: 0.8702, Accuracy: 0.6875\n",
      "Epoch [74/100], Step [6/13],               Loss: 0.6121, Accuracy: 0.765625\n",
      "Epoch [74/100], Step [7/13],               Loss: 0.7982, Accuracy: 0.71875\n",
      "Epoch [74/100], Step [8/13],               Loss: 0.6641, Accuracy: 0.765625\n",
      "Epoch [74/100], Step [9/13],               Loss: 0.9109, Accuracy: 0.6875\n",
      "Epoch [74/100], Step [10/13],               Loss: 0.6837, Accuracy: 0.75\n",
      "Epoch [74/100], Step [11/13],               Loss: 0.9419, Accuracy: 0.640625\n",
      "Epoch [74/100], Step [12/13],               Loss: 0.7271, Accuracy: 0.734375\n",
      "Epoch [74/100], Step [13/13],               Loss: 1.0572, Accuracy: 0.5161290168762207\n",
      "Epoch [75/100], Step [1/13],               Loss: 0.8269, Accuracy: 0.65625\n",
      "Epoch [75/100], Step [2/13],               Loss: 0.6857, Accuracy: 0.671875\n",
      "Epoch [75/100], Step [3/13],               Loss: 0.9335, Accuracy: 0.671875\n",
      "Epoch [75/100], Step [4/13],               Loss: 1.1372, Accuracy: 0.546875\n",
      "Epoch [75/100], Step [5/13],               Loss: 0.7884, Accuracy: 0.6875\n",
      "Epoch [75/100], Step [6/13],               Loss: 0.8046, Accuracy: 0.734375\n",
      "Epoch [75/100], Step [7/13],               Loss: 0.7936, Accuracy: 0.71875\n",
      "Epoch [75/100], Step [8/13],               Loss: 0.9536, Accuracy: 0.65625\n",
      "Epoch [75/100], Step [9/13],               Loss: 0.7927, Accuracy: 0.71875\n",
      "Epoch [75/100], Step [10/13],               Loss: 0.7888, Accuracy: 0.6875\n",
      "Epoch [75/100], Step [11/13],               Loss: 0.8270, Accuracy: 0.671875\n",
      "Epoch [75/100], Step [12/13],               Loss: 0.9856, Accuracy: 0.609375\n",
      "Epoch [75/100], Step [13/13],               Loss: 0.9273, Accuracy: 0.6129032373428345\n",
      "Epoch [76/100], Step [1/13],               Loss: 0.8549, Accuracy: 0.734375\n",
      "Epoch [76/100], Step [2/13],               Loss: 0.8520, Accuracy: 0.703125\n",
      "Epoch [76/100], Step [3/13],               Loss: 0.8917, Accuracy: 0.671875\n",
      "Epoch [76/100], Step [4/13],               Loss: 0.6689, Accuracy: 0.734375\n",
      "Epoch [76/100], Step [5/13],               Loss: 0.5884, Accuracy: 0.765625\n",
      "Epoch [76/100], Step [6/13],               Loss: 0.6583, Accuracy: 0.71875\n",
      "Epoch [76/100], Step [7/13],               Loss: 0.6419, Accuracy: 0.78125\n",
      "Epoch [76/100], Step [8/13],               Loss: 0.7142, Accuracy: 0.640625\n",
      "Epoch [76/100], Step [9/13],               Loss: 0.8734, Accuracy: 0.671875\n",
      "Epoch [76/100], Step [10/13],               Loss: 0.7480, Accuracy: 0.734375\n",
      "Epoch [76/100], Step [11/13],               Loss: 0.9507, Accuracy: 0.609375\n",
      "Epoch [76/100], Step [12/13],               Loss: 0.6244, Accuracy: 0.71875\n",
      "Epoch [76/100], Step [13/13],               Loss: 0.5378, Accuracy: 0.774193525314331\n",
      "Epoch [77/100], Step [1/13],               Loss: 0.6973, Accuracy: 0.78125\n",
      "Epoch [77/100], Step [2/13],               Loss: 0.6807, Accuracy: 0.703125\n",
      "Epoch [77/100], Step [3/13],               Loss: 0.7499, Accuracy: 0.734375\n",
      "Epoch [77/100], Step [4/13],               Loss: 0.7261, Accuracy: 0.71875\n",
      "Epoch [77/100], Step [5/13],               Loss: 0.5293, Accuracy: 0.828125\n",
      "Epoch [77/100], Step [6/13],               Loss: 0.7793, Accuracy: 0.734375\n",
      "Epoch [77/100], Step [7/13],               Loss: 0.6229, Accuracy: 0.71875\n",
      "Epoch [77/100], Step [8/13],               Loss: 0.5156, Accuracy: 0.8125\n",
      "Epoch [77/100], Step [9/13],               Loss: 0.7490, Accuracy: 0.75\n",
      "Epoch [77/100], Step [10/13],               Loss: 0.6905, Accuracy: 0.71875\n",
      "Epoch [77/100], Step [11/13],               Loss: 0.6626, Accuracy: 0.765625\n",
      "Epoch [77/100], Step [12/13],               Loss: 0.7828, Accuracy: 0.75\n",
      "Epoch [77/100], Step [13/13],               Loss: 0.8231, Accuracy: 0.6451612710952759\n",
      "Epoch [78/100], Step [1/13],               Loss: 0.5247, Accuracy: 0.828125\n",
      "Epoch [78/100], Step [2/13],               Loss: 0.5141, Accuracy: 0.796875\n",
      "Epoch [78/100], Step [3/13],               Loss: 0.5348, Accuracy: 0.78125\n",
      "Epoch [78/100], Step [4/13],               Loss: 0.5827, Accuracy: 0.796875\n",
      "Epoch [78/100], Step [5/13],               Loss: 0.7290, Accuracy: 0.734375\n",
      "Epoch [78/100], Step [6/13],               Loss: 0.5342, Accuracy: 0.765625\n",
      "Epoch [78/100], Step [7/13],               Loss: 0.8026, Accuracy: 0.671875\n",
      "Epoch [78/100], Step [8/13],               Loss: 0.6853, Accuracy: 0.765625\n",
      "Epoch [78/100], Step [9/13],               Loss: 0.5221, Accuracy: 0.84375\n",
      "Epoch [78/100], Step [10/13],               Loss: 0.5355, Accuracy: 0.796875\n",
      "Epoch [78/100], Step [11/13],               Loss: 0.6371, Accuracy: 0.796875\n",
      "Epoch [78/100], Step [12/13],               Loss: 0.5067, Accuracy: 0.796875\n",
      "Epoch [78/100], Step [13/13],               Loss: 0.2621, Accuracy: 0.9677419066429138\n",
      "Epoch [79/100], Step [1/13],               Loss: 0.5171, Accuracy: 0.875\n",
      "Epoch [79/100], Step [2/13],               Loss: 0.8179, Accuracy: 0.71875\n",
      "Epoch [79/100], Step [3/13],               Loss: 0.4970, Accuracy: 0.796875\n",
      "Epoch [79/100], Step [4/13],               Loss: 0.5419, Accuracy: 0.84375\n",
      "Epoch [79/100], Step [5/13],               Loss: 0.3581, Accuracy: 0.859375\n",
      "Epoch [79/100], Step [6/13],               Loss: 0.5647, Accuracy: 0.75\n",
      "Epoch [79/100], Step [7/13],               Loss: 0.4028, Accuracy: 0.8125\n",
      "Epoch [79/100], Step [8/13],               Loss: 0.8170, Accuracy: 0.6875\n",
      "Epoch [79/100], Step [9/13],               Loss: 0.8240, Accuracy: 0.671875\n",
      "Epoch [79/100], Step [10/13],               Loss: 1.0526, Accuracy: 0.578125\n",
      "Epoch [79/100], Step [11/13],               Loss: 0.9111, Accuracy: 0.703125\n",
      "Epoch [79/100], Step [12/13],               Loss: 0.8364, Accuracy: 0.796875\n",
      "Epoch [79/100], Step [13/13],               Loss: 0.6046, Accuracy: 0.7419354915618896\n",
      "Epoch [80/100], Step [1/13],               Loss: 0.5724, Accuracy: 0.8125\n",
      "Epoch [80/100], Step [2/13],               Loss: 0.6842, Accuracy: 0.796875\n",
      "Epoch [80/100], Step [3/13],               Loss: 0.9374, Accuracy: 0.6875\n",
      "Epoch [80/100], Step [4/13],               Loss: 0.5766, Accuracy: 0.828125\n",
      "Epoch [80/100], Step [5/13],               Loss: 0.7030, Accuracy: 0.71875\n",
      "Epoch [80/100], Step [6/13],               Loss: 0.7245, Accuracy: 0.6875\n",
      "Epoch [80/100], Step [7/13],               Loss: 1.0034, Accuracy: 0.5625\n",
      "Epoch [80/100], Step [8/13],               Loss: 0.7553, Accuracy: 0.703125\n",
      "Epoch [80/100], Step [9/13],               Loss: 0.6894, Accuracy: 0.640625\n",
      "Epoch [80/100], Step [10/13],               Loss: 0.7666, Accuracy: 0.6875\n",
      "Epoch [80/100], Step [11/13],               Loss: 0.7407, Accuracy: 0.734375\n",
      "Epoch [80/100], Step [12/13],               Loss: 0.6338, Accuracy: 0.78125\n",
      "Epoch [80/100], Step [13/13],               Loss: 0.6685, Accuracy: 0.6774193644523621\n",
      "Epoch [81/100], Step [1/13],               Loss: 0.7254, Accuracy: 0.671875\n",
      "Epoch [81/100], Step [2/13],               Loss: 0.6091, Accuracy: 0.703125\n",
      "Epoch [81/100], Step [3/13],               Loss: 0.6117, Accuracy: 0.78125\n",
      "Epoch [81/100], Step [4/13],               Loss: 0.7278, Accuracy: 0.78125\n",
      "Epoch [81/100], Step [5/13],               Loss: 0.4075, Accuracy: 0.859375\n",
      "Epoch [81/100], Step [6/13],               Loss: 0.5814, Accuracy: 0.8125\n",
      "Epoch [81/100], Step [7/13],               Loss: 0.3471, Accuracy: 0.859375\n",
      "Epoch [81/100], Step [8/13],               Loss: 0.5178, Accuracy: 0.765625\n",
      "Epoch [81/100], Step [9/13],               Loss: 0.5513, Accuracy: 0.796875\n",
      "Epoch [81/100], Step [10/13],               Loss: 0.6962, Accuracy: 0.71875\n",
      "Epoch [81/100], Step [11/13],               Loss: 0.4088, Accuracy: 0.78125\n",
      "Epoch [81/100], Step [12/13],               Loss: 0.7091, Accuracy: 0.78125\n",
      "Epoch [81/100], Step [13/13],               Loss: 0.9491, Accuracy: 0.6451612710952759\n",
      "Epoch [82/100], Step [1/13],               Loss: 0.5314, Accuracy: 0.8125\n",
      "Epoch [82/100], Step [2/13],               Loss: 0.6656, Accuracy: 0.75\n",
      "Epoch [82/100], Step [3/13],               Loss: 0.6039, Accuracy: 0.765625\n",
      "Epoch [82/100], Step [4/13],               Loss: 0.7465, Accuracy: 0.75\n",
      "Epoch [82/100], Step [5/13],               Loss: 0.8265, Accuracy: 0.65625\n",
      "Epoch [82/100], Step [6/13],               Loss: 0.6325, Accuracy: 0.71875\n",
      "Epoch [82/100], Step [7/13],               Loss: 0.7963, Accuracy: 0.6875\n",
      "Epoch [82/100], Step [8/13],               Loss: 0.6595, Accuracy: 0.734375\n",
      "Epoch [82/100], Step [9/13],               Loss: 0.9648, Accuracy: 0.671875\n",
      "Epoch [82/100], Step [10/13],               Loss: 0.4815, Accuracy: 0.8125\n",
      "Epoch [82/100], Step [11/13],               Loss: 0.5880, Accuracy: 0.75\n",
      "Epoch [82/100], Step [12/13],               Loss: 0.6856, Accuracy: 0.78125\n",
      "Epoch [82/100], Step [13/13],               Loss: 0.7667, Accuracy: 0.5806451439857483\n",
      "Epoch [83/100], Step [1/13],               Loss: 0.6613, Accuracy: 0.75\n",
      "Epoch [83/100], Step [2/13],               Loss: 0.5000, Accuracy: 0.828125\n",
      "Epoch [83/100], Step [3/13],               Loss: 0.5924, Accuracy: 0.8125\n",
      "Epoch [83/100], Step [4/13],               Loss: 0.5696, Accuracy: 0.796875\n",
      "Epoch [83/100], Step [5/13],               Loss: 0.6546, Accuracy: 0.8125\n",
      "Epoch [83/100], Step [6/13],               Loss: 0.8718, Accuracy: 0.65625\n",
      "Epoch [83/100], Step [7/13],               Loss: 0.4478, Accuracy: 0.8125\n",
      "Epoch [83/100], Step [8/13],               Loss: 0.6288, Accuracy: 0.75\n",
      "Epoch [83/100], Step [9/13],               Loss: 0.5437, Accuracy: 0.828125\n",
      "Epoch [83/100], Step [10/13],               Loss: 0.6858, Accuracy: 0.71875\n",
      "Epoch [83/100], Step [11/13],               Loss: 0.4123, Accuracy: 0.828125\n",
      "Epoch [83/100], Step [12/13],               Loss: 0.6253, Accuracy: 0.71875\n",
      "Epoch [83/100], Step [13/13],               Loss: 0.5480, Accuracy: 0.8387096524238586\n",
      "Epoch [84/100], Step [1/13],               Loss: 0.5906, Accuracy: 0.796875\n",
      "Epoch [84/100], Step [2/13],               Loss: 0.4645, Accuracy: 0.828125\n",
      "Epoch [84/100], Step [3/13],               Loss: 0.3924, Accuracy: 0.890625\n",
      "Epoch [84/100], Step [4/13],               Loss: 0.6365, Accuracy: 0.78125\n",
      "Epoch [84/100], Step [5/13],               Loss: 0.5060, Accuracy: 0.78125\n",
      "Epoch [84/100], Step [6/13],               Loss: 0.3829, Accuracy: 0.890625\n",
      "Epoch [84/100], Step [7/13],               Loss: 0.5847, Accuracy: 0.859375\n",
      "Epoch [84/100], Step [8/13],               Loss: 0.6342, Accuracy: 0.8125\n",
      "Epoch [84/100], Step [9/13],               Loss: 0.5083, Accuracy: 0.78125\n",
      "Epoch [84/100], Step [10/13],               Loss: 0.5817, Accuracy: 0.75\n",
      "Epoch [84/100], Step [11/13],               Loss: 0.4723, Accuracy: 0.8125\n",
      "Epoch [84/100], Step [12/13],               Loss: 0.3638, Accuracy: 0.84375\n",
      "Epoch [84/100], Step [13/13],               Loss: 0.5545, Accuracy: 0.7419354915618896\n",
      "Epoch [85/100], Step [1/13],               Loss: 0.5926, Accuracy: 0.75\n",
      "Epoch [85/100], Step [2/13],               Loss: 0.4011, Accuracy: 0.8125\n",
      "Epoch [85/100], Step [3/13],               Loss: 0.5482, Accuracy: 0.8125\n",
      "Epoch [85/100], Step [4/13],               Loss: 0.5904, Accuracy: 0.78125\n",
      "Epoch [85/100], Step [5/13],               Loss: 0.5589, Accuracy: 0.734375\n",
      "Epoch [85/100], Step [6/13],               Loss: 0.6998, Accuracy: 0.703125\n",
      "Epoch [85/100], Step [7/13],               Loss: 0.5436, Accuracy: 0.875\n",
      "Epoch [85/100], Step [8/13],               Loss: 0.6259, Accuracy: 0.765625\n",
      "Epoch [85/100], Step [9/13],               Loss: 0.7750, Accuracy: 0.71875\n",
      "Epoch [85/100], Step [10/13],               Loss: 0.8191, Accuracy: 0.671875\n",
      "Epoch [85/100], Step [11/13],               Loss: 0.7039, Accuracy: 0.734375\n",
      "Epoch [85/100], Step [12/13],               Loss: 0.6827, Accuracy: 0.75\n",
      "Epoch [85/100], Step [13/13],               Loss: 0.6033, Accuracy: 0.7096773982048035\n",
      "Epoch [86/100], Step [1/13],               Loss: 0.6569, Accuracy: 0.734375\n",
      "Epoch [86/100], Step [2/13],               Loss: 0.5057, Accuracy: 0.875\n",
      "Epoch [86/100], Step [3/13],               Loss: 0.6110, Accuracy: 0.75\n",
      "Epoch [86/100], Step [4/13],               Loss: 0.6066, Accuracy: 0.765625\n",
      "Epoch [86/100], Step [5/13],               Loss: 0.6691, Accuracy: 0.734375\n",
      "Epoch [86/100], Step [6/13],               Loss: 0.5857, Accuracy: 0.75\n",
      "Epoch [86/100], Step [7/13],               Loss: 0.6627, Accuracy: 0.765625\n",
      "Epoch [86/100], Step [8/13],               Loss: 0.4820, Accuracy: 0.796875\n",
      "Epoch [86/100], Step [9/13],               Loss: 0.5639, Accuracy: 0.765625\n",
      "Epoch [86/100], Step [10/13],               Loss: 0.6469, Accuracy: 0.78125\n",
      "Epoch [86/100], Step [11/13],               Loss: 0.5076, Accuracy: 0.8125\n",
      "Epoch [86/100], Step [12/13],               Loss: 0.7249, Accuracy: 0.75\n",
      "Epoch [86/100], Step [13/13],               Loss: 0.6673, Accuracy: 0.7096773982048035\n",
      "Epoch [87/100], Step [1/13],               Loss: 0.4193, Accuracy: 0.84375\n",
      "Epoch [87/100], Step [2/13],               Loss: 0.5688, Accuracy: 0.796875\n",
      "Epoch [87/100], Step [3/13],               Loss: 0.5273, Accuracy: 0.734375\n",
      "Epoch [87/100], Step [4/13],               Loss: 0.5441, Accuracy: 0.796875\n",
      "Epoch [87/100], Step [5/13],               Loss: 0.4870, Accuracy: 0.8125\n",
      "Epoch [87/100], Step [6/13],               Loss: 0.4919, Accuracy: 0.796875\n",
      "Epoch [87/100], Step [7/13],               Loss: 0.4232, Accuracy: 0.875\n",
      "Epoch [87/100], Step [8/13],               Loss: 1.0938, Accuracy: 0.625\n",
      "Epoch [87/100], Step [9/13],               Loss: 0.6070, Accuracy: 0.796875\n",
      "Epoch [87/100], Step [10/13],               Loss: 0.5025, Accuracy: 0.828125\n",
      "Epoch [87/100], Step [11/13],               Loss: 0.6204, Accuracy: 0.765625\n",
      "Epoch [87/100], Step [12/13],               Loss: 0.7451, Accuracy: 0.65625\n",
      "Epoch [87/100], Step [13/13],               Loss: 0.9945, Accuracy: 0.6129032373428345\n",
      "Epoch [88/100], Step [1/13],               Loss: 0.9258, Accuracy: 0.671875\n",
      "Epoch [88/100], Step [2/13],               Loss: 0.5945, Accuracy: 0.84375\n",
      "Epoch [88/100], Step [3/13],               Loss: 0.4180, Accuracy: 0.859375\n",
      "Epoch [88/100], Step [4/13],               Loss: 0.4807, Accuracy: 0.828125\n",
      "Epoch [88/100], Step [5/13],               Loss: 0.7058, Accuracy: 0.75\n",
      "Epoch [88/100], Step [6/13],               Loss: 0.6476, Accuracy: 0.765625\n",
      "Epoch [88/100], Step [7/13],               Loss: 0.6852, Accuracy: 0.71875\n",
      "Epoch [88/100], Step [8/13],               Loss: 0.3574, Accuracy: 0.921875\n",
      "Epoch [88/100], Step [9/13],               Loss: 0.5283, Accuracy: 0.828125\n",
      "Epoch [88/100], Step [10/13],               Loss: 0.6158, Accuracy: 0.75\n",
      "Epoch [88/100], Step [11/13],               Loss: 0.6301, Accuracy: 0.6875\n",
      "Epoch [88/100], Step [12/13],               Loss: 0.5417, Accuracy: 0.75\n",
      "Epoch [88/100], Step [13/13],               Loss: 0.3663, Accuracy: 0.8064516186714172\n",
      "Epoch [89/100], Step [1/13],               Loss: 0.3731, Accuracy: 0.84375\n",
      "Epoch [89/100], Step [2/13],               Loss: 0.4586, Accuracy: 0.828125\n",
      "Epoch [89/100], Step [3/13],               Loss: 0.6601, Accuracy: 0.71875\n",
      "Epoch [89/100], Step [4/13],               Loss: 0.3766, Accuracy: 0.875\n",
      "Epoch [89/100], Step [5/13],               Loss: 0.5838, Accuracy: 0.734375\n",
      "Epoch [89/100], Step [6/13],               Loss: 0.5654, Accuracy: 0.78125\n",
      "Epoch [89/100], Step [7/13],               Loss: 0.5991, Accuracy: 0.765625\n",
      "Epoch [89/100], Step [8/13],               Loss: 0.5040, Accuracy: 0.78125\n",
      "Epoch [89/100], Step [9/13],               Loss: 0.3367, Accuracy: 0.90625\n",
      "Epoch [89/100], Step [10/13],               Loss: 0.3141, Accuracy: 0.828125\n",
      "Epoch [89/100], Step [11/13],               Loss: 0.4093, Accuracy: 0.828125\n",
      "Epoch [89/100], Step [12/13],               Loss: 0.4347, Accuracy: 0.828125\n",
      "Epoch [89/100], Step [13/13],               Loss: 0.4688, Accuracy: 0.7419354915618896\n",
      "Epoch [90/100], Step [1/13],               Loss: 0.3356, Accuracy: 0.84375\n",
      "Epoch [90/100], Step [2/13],               Loss: 0.4299, Accuracy: 0.828125\n",
      "Epoch [90/100], Step [3/13],               Loss: 0.2829, Accuracy: 0.859375\n",
      "Epoch [90/100], Step [4/13],               Loss: 0.3274, Accuracy: 0.90625\n",
      "Epoch [90/100], Step [5/13],               Loss: 0.6026, Accuracy: 0.75\n",
      "Epoch [90/100], Step [6/13],               Loss: 0.2426, Accuracy: 0.90625\n",
      "Epoch [90/100], Step [7/13],               Loss: 0.4298, Accuracy: 0.828125\n",
      "Epoch [90/100], Step [8/13],               Loss: 0.4638, Accuracy: 0.859375\n",
      "Epoch [90/100], Step [9/13],               Loss: 0.4570, Accuracy: 0.84375\n",
      "Epoch [90/100], Step [10/13],               Loss: 0.5509, Accuracy: 0.8125\n",
      "Epoch [90/100], Step [11/13],               Loss: 0.2960, Accuracy: 0.90625\n",
      "Epoch [90/100], Step [12/13],               Loss: 0.3614, Accuracy: 0.828125\n",
      "Epoch [90/100], Step [13/13],               Loss: 0.2757, Accuracy: 0.9032257795333862\n",
      "Epoch [91/100], Step [1/13],               Loss: 0.2242, Accuracy: 0.921875\n",
      "Epoch [91/100], Step [2/13],               Loss: 0.3246, Accuracy: 0.90625\n",
      "Epoch [91/100], Step [3/13],               Loss: 0.3486, Accuracy: 0.84375\n",
      "Epoch [91/100], Step [4/13],               Loss: 0.3489, Accuracy: 0.890625\n",
      "Epoch [91/100], Step [5/13],               Loss: 0.3549, Accuracy: 0.875\n",
      "Epoch [91/100], Step [6/13],               Loss: 0.4145, Accuracy: 0.84375\n",
      "Epoch [91/100], Step [7/13],               Loss: 0.2374, Accuracy: 0.90625\n",
      "Epoch [91/100], Step [8/13],               Loss: 0.2147, Accuracy: 0.9375\n",
      "Epoch [91/100], Step [9/13],               Loss: 0.5804, Accuracy: 0.828125\n",
      "Epoch [91/100], Step [10/13],               Loss: 0.2879, Accuracy: 0.90625\n",
      "Epoch [91/100], Step [11/13],               Loss: 0.4475, Accuracy: 0.859375\n",
      "Epoch [91/100], Step [12/13],               Loss: 0.2015, Accuracy: 0.90625\n",
      "Epoch [91/100], Step [13/13],               Loss: 0.3737, Accuracy: 0.8387096524238586\n",
      "Epoch [92/100], Step [1/13],               Loss: 0.1474, Accuracy: 0.953125\n",
      "Epoch [92/100], Step [2/13],               Loss: 0.3996, Accuracy: 0.859375\n",
      "Epoch [92/100], Step [3/13],               Loss: 0.4308, Accuracy: 0.796875\n",
      "Epoch [92/100], Step [4/13],               Loss: 0.4653, Accuracy: 0.84375\n",
      "Epoch [92/100], Step [5/13],               Loss: 0.3885, Accuracy: 0.8125\n",
      "Epoch [92/100], Step [6/13],               Loss: 0.4847, Accuracy: 0.796875\n",
      "Epoch [92/100], Step [7/13],               Loss: 0.4206, Accuracy: 0.8125\n",
      "Epoch [92/100], Step [8/13],               Loss: 0.3434, Accuracy: 0.890625\n",
      "Epoch [92/100], Step [9/13],               Loss: 0.2680, Accuracy: 0.890625\n",
      "Epoch [92/100], Step [10/13],               Loss: 0.4073, Accuracy: 0.8125\n",
      "Epoch [92/100], Step [11/13],               Loss: 0.5810, Accuracy: 0.796875\n",
      "Epoch [92/100], Step [12/13],               Loss: 0.3256, Accuracy: 0.859375\n",
      "Epoch [92/100], Step [13/13],               Loss: 0.3609, Accuracy: 0.8709677457809448\n",
      "Epoch [93/100], Step [1/13],               Loss: 0.2620, Accuracy: 0.90625\n",
      "Epoch [93/100], Step [2/13],               Loss: 0.3979, Accuracy: 0.8125\n",
      "Epoch [93/100], Step [3/13],               Loss: 0.3313, Accuracy: 0.859375\n",
      "Epoch [93/100], Step [4/13],               Loss: 0.5973, Accuracy: 0.765625\n",
      "Epoch [93/100], Step [5/13],               Loss: 0.4006, Accuracy: 0.890625\n",
      "Epoch [93/100], Step [6/13],               Loss: 0.3286, Accuracy: 0.84375\n",
      "Epoch [93/100], Step [7/13],               Loss: 0.4493, Accuracy: 0.796875\n",
      "Epoch [93/100], Step [8/13],               Loss: 0.2787, Accuracy: 0.921875\n",
      "Epoch [93/100], Step [9/13],               Loss: 0.4606, Accuracy: 0.8125\n",
      "Epoch [93/100], Step [10/13],               Loss: 0.2751, Accuracy: 0.875\n",
      "Epoch [93/100], Step [11/13],               Loss: 0.6126, Accuracy: 0.734375\n",
      "Epoch [93/100], Step [12/13],               Loss: 0.3828, Accuracy: 0.890625\n",
      "Epoch [93/100], Step [13/13],               Loss: 0.3523, Accuracy: 0.8709677457809448\n",
      "Epoch [94/100], Step [1/13],               Loss: 0.3634, Accuracy: 0.828125\n",
      "Epoch [94/100], Step [2/13],               Loss: 0.4527, Accuracy: 0.796875\n",
      "Epoch [94/100], Step [3/13],               Loss: 0.4008, Accuracy: 0.84375\n",
      "Epoch [94/100], Step [4/13],               Loss: 0.2543, Accuracy: 0.90625\n",
      "Epoch [94/100], Step [5/13],               Loss: 0.3995, Accuracy: 0.84375\n",
      "Epoch [94/100], Step [6/13],               Loss: 0.2609, Accuracy: 0.90625\n",
      "Epoch [94/100], Step [7/13],               Loss: 0.5842, Accuracy: 0.78125\n",
      "Epoch [94/100], Step [8/13],               Loss: 0.4653, Accuracy: 0.796875\n",
      "Epoch [94/100], Step [9/13],               Loss: 0.5640, Accuracy: 0.796875\n",
      "Epoch [94/100], Step [10/13],               Loss: 0.3685, Accuracy: 0.859375\n",
      "Epoch [94/100], Step [11/13],               Loss: 0.3470, Accuracy: 0.8125\n",
      "Epoch [94/100], Step [12/13],               Loss: 0.4586, Accuracy: 0.828125\n",
      "Epoch [94/100], Step [13/13],               Loss: 0.7286, Accuracy: 0.6451612710952759\n",
      "Epoch [95/100], Step [1/13],               Loss: 0.2238, Accuracy: 0.90625\n",
      "Epoch [95/100], Step [2/13],               Loss: 0.8536, Accuracy: 0.640625\n",
      "Epoch [95/100], Step [3/13],               Loss: 1.0921, Accuracy: 0.640625\n",
      "Epoch [95/100], Step [4/13],               Loss: 0.5670, Accuracy: 0.75\n",
      "Epoch [95/100], Step [5/13],               Loss: 0.6454, Accuracy: 0.796875\n",
      "Epoch [95/100], Step [6/13],               Loss: 0.8217, Accuracy: 0.734375\n",
      "Epoch [95/100], Step [7/13],               Loss: 1.6005, Accuracy: 0.671875\n",
      "Epoch [95/100], Step [8/13],               Loss: 0.9315, Accuracy: 0.671875\n",
      "Epoch [95/100], Step [9/13],               Loss: 0.7466, Accuracy: 0.6875\n",
      "Epoch [95/100], Step [10/13],               Loss: 0.6434, Accuracy: 0.71875\n",
      "Epoch [95/100], Step [11/13],               Loss: 0.8545, Accuracy: 0.640625\n",
      "Epoch [95/100], Step [12/13],               Loss: 0.8521, Accuracy: 0.6875\n",
      "Epoch [95/100], Step [13/13],               Loss: 0.8302, Accuracy: 0.6451612710952759\n",
      "Epoch [96/100], Step [1/13],               Loss: 0.7784, Accuracy: 0.671875\n",
      "Epoch [96/100], Step [2/13],               Loss: 0.8583, Accuracy: 0.671875\n",
      "Epoch [96/100], Step [3/13],               Loss: 0.9236, Accuracy: 0.5625\n",
      "Epoch [96/100], Step [4/13],               Loss: 0.8049, Accuracy: 0.671875\n",
      "Epoch [96/100], Step [5/13],               Loss: 0.8175, Accuracy: 0.78125\n",
      "Epoch [96/100], Step [6/13],               Loss: 0.5985, Accuracy: 0.78125\n",
      "Epoch [96/100], Step [7/13],               Loss: 0.6064, Accuracy: 0.828125\n",
      "Epoch [96/100], Step [8/13],               Loss: 0.5585, Accuracy: 0.828125\n",
      "Epoch [96/100], Step [9/13],               Loss: 0.5924, Accuracy: 0.765625\n",
      "Epoch [96/100], Step [10/13],               Loss: 0.7113, Accuracy: 0.71875\n",
      "Epoch [96/100], Step [11/13],               Loss: 0.6114, Accuracy: 0.765625\n",
      "Epoch [96/100], Step [12/13],               Loss: 0.4220, Accuracy: 0.859375\n",
      "Epoch [96/100], Step [13/13],               Loss: 0.9020, Accuracy: 0.7096773982048035\n",
      "Epoch [97/100], Step [1/13],               Loss: 0.4024, Accuracy: 0.875\n",
      "Epoch [97/100], Step [2/13],               Loss: 0.4072, Accuracy: 0.828125\n",
      "Epoch [97/100], Step [3/13],               Loss: 0.3731, Accuracy: 0.921875\n",
      "Epoch [97/100], Step [4/13],               Loss: 0.3414, Accuracy: 0.890625\n",
      "Epoch [97/100], Step [5/13],               Loss: 0.4796, Accuracy: 0.859375\n",
      "Epoch [97/100], Step [6/13],               Loss: 0.4753, Accuracy: 0.859375\n",
      "Epoch [97/100], Step [7/13],               Loss: 0.2683, Accuracy: 0.9375\n",
      "Epoch [97/100], Step [8/13],               Loss: 0.4621, Accuracy: 0.859375\n",
      "Epoch [97/100], Step [9/13],               Loss: 0.3102, Accuracy: 0.875\n",
      "Epoch [97/100], Step [10/13],               Loss: 0.3675, Accuracy: 0.84375\n",
      "Epoch [97/100], Step [11/13],               Loss: 0.3052, Accuracy: 0.84375\n",
      "Epoch [97/100], Step [12/13],               Loss: 0.3806, Accuracy: 0.828125\n",
      "Epoch [97/100], Step [13/13],               Loss: 0.2005, Accuracy: 0.9354838728904724\n",
      "Epoch [98/100], Step [1/13],               Loss: 0.2523, Accuracy: 0.90625\n",
      "Epoch [98/100], Step [2/13],               Loss: 0.5277, Accuracy: 0.78125\n",
      "Epoch [98/100], Step [3/13],               Loss: 0.3054, Accuracy: 0.875\n",
      "Epoch [98/100], Step [4/13],               Loss: 0.3679, Accuracy: 0.84375\n",
      "Epoch [98/100], Step [5/13],               Loss: 0.3899, Accuracy: 0.875\n",
      "Epoch [98/100], Step [6/13],               Loss: 0.3642, Accuracy: 0.890625\n",
      "Epoch [98/100], Step [7/13],               Loss: 0.2428, Accuracy: 0.859375\n",
      "Epoch [98/100], Step [8/13],               Loss: 0.2788, Accuracy: 0.84375\n",
      "Epoch [98/100], Step [9/13],               Loss: 0.4319, Accuracy: 0.859375\n",
      "Epoch [98/100], Step [10/13],               Loss: 0.2921, Accuracy: 0.890625\n",
      "Epoch [98/100], Step [11/13],               Loss: 0.3806, Accuracy: 0.828125\n",
      "Epoch [98/100], Step [12/13],               Loss: 0.3287, Accuracy: 0.875\n",
      "Epoch [98/100], Step [13/13],               Loss: 0.2394, Accuracy: 0.9032257795333862\n",
      "Epoch [99/100], Step [1/13],               Loss: 0.2540, Accuracy: 0.890625\n",
      "Epoch [99/100], Step [2/13],               Loss: 0.3761, Accuracy: 0.84375\n",
      "Epoch [99/100], Step [3/13],               Loss: 0.3742, Accuracy: 0.796875\n",
      "Epoch [99/100], Step [4/13],               Loss: 0.2946, Accuracy: 0.90625\n",
      "Epoch [99/100], Step [5/13],               Loss: 0.3904, Accuracy: 0.859375\n",
      "Epoch [99/100], Step [6/13],               Loss: 0.2167, Accuracy: 0.9375\n",
      "Epoch [99/100], Step [7/13],               Loss: 0.2429, Accuracy: 0.890625\n",
      "Epoch [99/100], Step [8/13],               Loss: 0.2795, Accuracy: 0.84375\n",
      "Epoch [99/100], Step [9/13],               Loss: 0.2313, Accuracy: 0.890625\n",
      "Epoch [99/100], Step [10/13],               Loss: 0.2210, Accuracy: 0.921875\n",
      "Epoch [99/100], Step [11/13],               Loss: 0.2009, Accuracy: 0.953125\n",
      "Epoch [99/100], Step [12/13],               Loss: 1.1333, Accuracy: 0.8125\n",
      "Epoch [99/100], Step [13/13],               Loss: 0.6721, Accuracy: 0.774193525314331\n",
      "Epoch [100/100], Step [1/13],               Loss: 0.5732, Accuracy: 0.796875\n",
      "Epoch [100/100], Step [2/13],               Loss: 0.4835, Accuracy: 0.859375\n",
      "Epoch [100/100], Step [3/13],               Loss: 0.7426, Accuracy: 0.734375\n",
      "Epoch [100/100], Step [4/13],               Loss: 0.4212, Accuracy: 0.890625\n",
      "Epoch [100/100], Step [5/13],               Loss: 0.6591, Accuracy: 0.71875\n",
      "Epoch [100/100], Step [6/13],               Loss: 0.4859, Accuracy: 0.8125\n",
      "Epoch [100/100], Step [7/13],               Loss: 0.5569, Accuracy: 0.75\n",
      "Epoch [100/100], Step [8/13],               Loss: 0.6228, Accuracy: 0.78125\n",
      "Epoch [100/100], Step [9/13],               Loss: 0.3448, Accuracy: 0.859375\n",
      "Epoch [100/100], Step [10/13],               Loss: 0.5024, Accuracy: 0.828125\n",
      "Epoch [100/100], Step [11/13],               Loss: 0.4426, Accuracy: 0.84375\n",
      "Epoch [100/100], Step [12/13],               Loss: 0.4511, Accuracy: 0.8125\n",
      "Epoch [100/100], Step [13/13],               Loss: 0.4914, Accuracy: 0.8064516186714172\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model, loss, and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataloader_train):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        outputs = outputs.float()\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # assess accuracy\n",
    "        softmax_func = nn.Softmax(dim=1)\n",
    "        softmax = softmax_func(outputs)\n",
    "        acc_vector = torch.stack([(torch.argmax(softmax[iidx])==torch.argmax(labels[iidx])) for iidx in np.arange(0,labels.shape[0])], dim=0).flatten()\n",
    "        accuracy = torch.sum(acc_vector) / labels.shape[0]\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(dataloader_train)}], \\\n",
    "              Loss: {loss.item():.4f}, Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
